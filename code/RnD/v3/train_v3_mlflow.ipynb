{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PortfolioConstructor import PortfolioConstructor\n",
    "from ExchnageEnv import MarketEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda') \n",
    "    torch.get_default_device()\n",
    "    device = 'cuda'\n",
    "    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/naradaw/dev/Charles_Schwab/data/symbol_universe/snp_unique_100_2019\", \"rb\") as fp:\n",
    "    symbol_universe = pickle.load(fp)\n",
    "    \n",
    "symbol_universe = symbol_universe[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_path = \"/home/naradaw/dev/Charles_Schwab/data/w_features/v1/2024_10_31/feature_set_2024_10_31_11_18.pkl\"\n",
    "\n",
    "with open(feature_set_path, 'rb') as f:\n",
    "    feature_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/naradaw/dev/Charles_Schwab/data/w_features/v1/2024_10_31/dataset_sqs_2024_10_31_11_18.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 15:30:15 INFO mlflow.tracking.fluent: Experiment with name '/portfolio-contructor-v4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/naradaw/dev/Charles_Schwab/code/RnD/v4/mlflow_experiments/589106785306301247', creation_time=1731319215217, experiment_id='589106785306301247', last_update_time=1731319215217, lifecycle_stage='active', name='/portfolio-contructor-v4', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_tracking_uri = 'file:/home/naradaw/dev/Charles_Schwab/code/RnD/v4/mlflow_experiments'\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "experiment_name = \"/portfolio-contructor-v4\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1000\n",
    "eval_step = 1\n",
    "train_step = 1\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "symbol_universe= symbol_universe\n",
    "num_features= len(feature_set)\n",
    "d_model = 88\n",
    "nheads = 1\n",
    "num_transformer_layers = 2\n",
    "\n",
    "episode_duration= 12   \n",
    "holding_period = 1\n",
    "train_test_split= 0.7\n",
    "symbol_universe = symbol_universe\n",
    "feature_set= feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol_universe = random.choices(symbol_universe, k = 20)\n",
    "# symbol_universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sharpe ratio measures the excess return of the portfolio over the \n",
    "volatility of it -> risk adjusted performance\n",
    "'''\n",
    "\n",
    "def sharp_ratio_(rewards, tran_costs):\n",
    "\n",
    "\t# rewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env):\n",
    "    is_end = False\n",
    "    rewards = []\n",
    "    tran_costs = []\n",
    "    \n",
    "    env.reset(mode = \"test\")\n",
    "    state = env.get_state()\n",
    "\n",
    "    print(\"\")\n",
    "    while not is_end:\n",
    "        _, allocations = model(state)\n",
    "        state, reward, is_end, tran_cost = env.step(allocations)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        tran_costs.append(tran_cost)\n",
    "\n",
    "    sharp_ratio = sharp_ratio_(rewards, tran_costs)\n",
    "\n",
    "    return sharp_ratio, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# mlflow.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "training model --\n",
      "Step 0: last loss = -0.12630\n",
      "eval step --\n",
      "\n",
      "Step 0: val_rewards = 0.5809145675615469\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 1: last loss = -0.17433\n",
      "eval step --\n",
      "\n",
      "Step 1: val_rewards = 0.7313471853873924\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 2: last loss = -0.66412\n",
      "eval step --\n",
      "\n",
      "Step 2: val_rewards = 0.7141158193210443\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 3: last loss = -0.09478\n",
      "eval step --\n",
      "\n",
      "Step 3: val_rewards = 0.693166598948712\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 4: last loss = -0.14319\n",
      "eval step --\n",
      "\n",
      "Step 4: val_rewards = 0.6993151464882541\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 5: last loss = -0.09449\n",
      "eval step --\n",
      "\n",
      "Step 5: val_rewards = 0.7042044318487124\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 6: last loss = -0.32841\n",
      "eval step --\n",
      "\n",
      "Step 6: val_rewards = 0.6996054253558789\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 7: last loss = -0.10296\n",
      "eval step --\n",
      "\n",
      "Step 7: val_rewards = 0.8000245412656445\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 8: last loss = -0.12399\n",
      "eval step --\n",
      "\n",
      "Step 8: val_rewards = 0.6730591156741221\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 9: last loss = -0.06439\n",
      "eval step --\n",
      "\n",
      "Step 9: val_rewards = 0.48140888922869285\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 10: last loss = -0.11248\n",
      "eval step --\n",
      "\n",
      "Step 10: val_rewards = 0.7472814404672604\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 11: last loss = -0.24921\n",
      "eval step --\n",
      "\n",
      "Step 11: val_rewards = 0.6989342008655698\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 12: last loss = -0.40649\n",
      "eval step --\n",
      "\n",
      "Step 12: val_rewards = 0.6991284765797572\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 13: last loss = -0.33188\n",
      "eval step --\n",
      "\n",
      "Step 13: val_rewards = 0.705238506482108\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 14: last loss = -0.48393\n",
      "eval step --\n",
      "\n",
      "Step 14: val_rewards = 0.7053643377420716\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 15: last loss = -0.04928\n",
      "eval step --\n",
      "\n",
      "Step 15: val_rewards = 0.705415881209632\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 16: last loss = -0.63970\n",
      "eval step --\n",
      "\n",
      "Step 16: val_rewards = 0.7071401071296028\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 17: last loss = -0.78751\n",
      "eval step --\n",
      "\n",
      "Step 17: val_rewards = 0.6779936895483161\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 18: last loss = -0.21827\n",
      "eval step --\n",
      "\n",
      "Step 18: val_rewards = 0.6908651411466519\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 19: last loss = -0.34821\n",
      "eval step --\n",
      "\n",
      "Step 19: val_rewards = 0.8324766135803907\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 20: last loss = 0.01470\n",
      "eval step --\n",
      "\n",
      "Step 20: val_rewards = 0.6018710399908634\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 21: last loss = 0.00620\n",
      "eval step --\n",
      "\n",
      "Step 21: val_rewards = 0.7401491403690449\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 22: last loss = -0.96513\n",
      "eval step --\n",
      "\n",
      "Step 22: val_rewards = 0.7555688984936786\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 23: last loss = -0.31938\n",
      "eval step --\n",
      "\n",
      "Step 23: val_rewards = 0.7751709746425504\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 24: last loss = -0.13593\n",
      "eval step --\n",
      "\n",
      "Step 24: val_rewards = 0.7751718961968166\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 25: last loss = -0.26142\n",
      "eval step --\n",
      "\n",
      "Step 25: val_rewards = 0.7507530904255124\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 26: last loss = -0.55386\n",
      "eval step --\n",
      "\n",
      "Step 26: val_rewards = 0.7507542619599535\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 27: last loss = 0.05223\n",
      "eval step --\n",
      "\n",
      "Step 27: val_rewards = 0.7739176644556943\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 28: last loss = -0.00548\n",
      "eval step --\n",
      "\n",
      "Step 28: val_rewards = 0.7346283101881512\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 29: last loss = -0.25299\n",
      "eval step --\n",
      "\n",
      "Step 29: val_rewards = 0.7507557955284745\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 30: last loss = -0.02124\n",
      "eval step --\n",
      "\n",
      "Step 30: val_rewards = 0.7507556886152316\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 31: last loss = -0.21705\n",
      "eval step --\n",
      "\n",
      "Step 31: val_rewards = 0.7346279922750657\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 32: last loss = -0.03536\n",
      "eval step --\n",
      "\n",
      "Step 32: val_rewards = 0.7507546292275524\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 33: last loss = 0.09367\n",
      "eval step --\n",
      "\n",
      "Step 33: val_rewards = 0.6992839444021146\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 34: last loss = -0.25183\n",
      "eval step --\n",
      "\n",
      "Step 34: val_rewards = 0.8498218308649571\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 35: last loss = 0.01083\n",
      "eval step --\n",
      "\n",
      "Step 35: val_rewards = 0.9063246429868786\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 36: last loss = -0.31491\n",
      "eval step --\n",
      "\n",
      "Step 36: val_rewards = 0.9017674700437008\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 37: last loss = -0.22374\n",
      "eval step --\n",
      "\n",
      "Step 37: val_rewards = 0.684783646211054\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 38: last loss = -0.01639\n",
      "eval step --\n",
      "\n",
      "Step 38: val_rewards = 0.6962511310566083\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 39: last loss = -0.14202\n",
      "eval step --\n",
      "\n",
      "Step 39: val_rewards = 0.6051905989299784\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 40: last loss = -0.22204\n",
      "eval step --\n",
      "\n",
      "Step 40: val_rewards = 0.6696159159775985\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 41: last loss = -0.04603\n",
      "eval step --\n",
      "\n",
      "Step 41: val_rewards = 0.35383361569431687\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 42: last loss = -0.84299\n",
      "eval step --\n",
      "\n",
      "Step 42: val_rewards = 0.6005716681736117\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 43: last loss = -0.32568\n",
      "eval step --\n",
      "\n",
      "Step 43: val_rewards = 0.4071055089206877\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 44: last loss = -0.24450\n",
      "eval step --\n",
      "\n",
      "Step 44: val_rewards = 0.2597115943813291\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 45: last loss = -0.34821\n",
      "eval step --\n",
      "\n",
      "Step 45: val_rewards = 0.16935941816159167\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 46: last loss = -0.52146\n",
      "eval step --\n",
      "\n",
      "Step 46: val_rewards = 0.18089396554595968\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 47: last loss = -0.49666\n",
      "eval step --\n",
      "\n",
      "Step 47: val_rewards = 0.2589761915471035\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 48: last loss = -0.50876\n",
      "eval step --\n",
      "\n",
      "Step 48: val_rewards = 0.16317495293805473\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 49: last loss = -0.52833\n",
      "eval step --\n",
      "\n",
      "Step 49: val_rewards = 0.1291451603045222\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 50: last loss = -0.31522\n",
      "eval step --\n",
      "\n",
      "Step 50: val_rewards = 0.2853888251656206\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 51: last loss = -0.32502\n",
      "eval step --\n",
      "\n",
      "Step 51: val_rewards = 0.2869958957776973\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 52: last loss = -0.42661\n",
      "eval step --\n",
      "\n",
      "Step 52: val_rewards = 0.29409926955314597\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 53: last loss = -0.68697\n",
      "eval step --\n",
      "\n",
      "Step 53: val_rewards = 0.2771056019434677\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 54: last loss = -0.07771\n",
      "eval step --\n",
      "\n",
      "Step 54: val_rewards = 0.2570532706622231\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 55: last loss = -0.05434\n",
      "eval step --\n",
      "\n",
      "Step 55: val_rewards = 0.2840489869998656\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 56: last loss = -0.11241\n",
      "eval step --\n",
      "\n",
      "Step 56: val_rewards = 0.27306436941716855\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 57: last loss = -0.17408\n",
      "eval step --\n",
      "\n",
      "Step 57: val_rewards = 0.42059101545534605\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 58: last loss = -0.27343\n",
      "eval step --\n",
      "\n",
      "Step 58: val_rewards = 0.48737372128526424\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 59: last loss = -0.28327\n",
      "eval step --\n",
      "\n",
      "Step 59: val_rewards = 0.24840780504800183\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 60: last loss = -0.51536\n",
      "eval step --\n",
      "\n",
      "Step 60: val_rewards = 0.3067242569038228\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 61: last loss = -0.28412\n",
      "eval step --\n",
      "\n",
      "Step 61: val_rewards = 0.3089024582723327\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 62: last loss = 0.13101\n",
      "eval step --\n",
      "\n",
      "Step 62: val_rewards = 0.2703807265272676\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 63: last loss = 0.10337\n",
      "eval step --\n",
      "\n",
      "Step 63: val_rewards = 0.4439203178894322\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 64: last loss = -0.36866\n",
      "eval step --\n",
      "\n",
      "Step 64: val_rewards = 0.3191341690918865\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 65: last loss = -0.81188\n",
      "eval step --\n",
      "\n",
      "Step 65: val_rewards = 0.39563307339612847\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 66: last loss = -0.23222\n",
      "eval step --\n",
      "\n",
      "Step 66: val_rewards = 0.5389109770440466\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 67: last loss = -0.11514\n",
      "eval step --\n",
      "\n",
      "Step 67: val_rewards = 0.5834176584192385\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 68: last loss = -0.37699\n",
      "eval step --\n",
      "\n",
      "Step 68: val_rewards = 0.55715938857575\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 69: last loss = -0.69623\n",
      "eval step --\n",
      "\n",
      "Step 69: val_rewards = 0.4440862377216684\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 70: last loss = -0.20010\n",
      "eval step --\n",
      "\n",
      "Step 70: val_rewards = 0.6818156435735053\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 71: last loss = -0.10249\n",
      "eval step --\n",
      "\n",
      "Step 71: val_rewards = 0.6960047020281949\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 72: last loss = -0.43179\n",
      "eval step --\n",
      "\n",
      "Step 72: val_rewards = 0.6901533841591292\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 73: last loss = -0.37383\n",
      "eval step --\n",
      "\n",
      "Step 73: val_rewards = 0.6497075199566206\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 74: last loss = 0.03197\n",
      "eval step --\n",
      "\n",
      "Step 74: val_rewards = 0.6985036723900491\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 75: last loss = 0.06918\n",
      "eval step --\n",
      "\n",
      "Step 75: val_rewards = 0.698502540141945\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 76: last loss = 0.02033\n",
      "eval step --\n",
      "\n",
      "Step 76: val_rewards = 0.6495672994720993\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 77: last loss = -0.76112\n",
      "eval step --\n",
      "\n",
      "Step 77: val_rewards = 0.5777860284239786\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 78: last loss = -0.10442\n",
      "eval step --\n",
      "\n",
      "Step 78: val_rewards = 0.5821655328078228\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 79: last loss = 0.06444\n",
      "eval step --\n",
      "\n",
      "Step 79: val_rewards = 0.5975042367572002\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 80: last loss = 0.30836\n",
      "eval step --\n",
      "\n",
      "Step 80: val_rewards = 0.6778390672440006\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 81: last loss = 0.16772\n",
      "eval step --\n",
      "\n",
      "Step 81: val_rewards = 0.581510822058779\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 82: last loss = -0.54965\n",
      "eval step --\n",
      "\n",
      "Step 82: val_rewards = 0.7491025264273488\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 83: last loss = 0.00010\n",
      "eval step --\n",
      "\n",
      "Step 83: val_rewards = 0.7690290368139615\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 84: last loss = -0.30694\n",
      "eval step --\n",
      "\n",
      "Step 84: val_rewards = 0.75931984459262\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 85: last loss = -0.14157\n",
      "eval step --\n",
      "\n",
      "Step 85: val_rewards = 0.6613432944303733\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 86: last loss = -0.20583\n",
      "eval step --\n",
      "\n",
      "Step 86: val_rewards = 0.4061469648286217\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 87: last loss = -0.13083\n",
      "eval step --\n",
      "\n",
      "Step 87: val_rewards = 0.249394931032159\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 88: last loss = -0.05915\n",
      "eval step --\n",
      "\n",
      "Step 88: val_rewards = 0.46546294164331836\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 89: last loss = -0.20456\n",
      "eval step --\n",
      "\n",
      "Step 89: val_rewards = 0.459192740948674\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 90: last loss = -0.27805\n",
      "eval step --\n",
      "\n",
      "Step 90: val_rewards = 0.6827438496375067\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 91: last loss = -0.17385\n",
      "eval step --\n",
      "\n",
      "Step 91: val_rewards = 0.7206273652839852\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 92: last loss = -0.13471\n",
      "eval step --\n",
      "\n",
      "Step 92: val_rewards = 0.7177581401395973\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 93: last loss = -0.16860\n",
      "eval step --\n",
      "\n",
      "Step 93: val_rewards = 0.6969388806710949\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 94: last loss = -0.26049\n",
      "eval step --\n",
      "\n",
      "Step 94: val_rewards = 0.7395676323168828\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 95: last loss = -0.11085\n",
      "eval step --\n",
      "\n",
      "Step 95: val_rewards = 0.7145793390083824\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 96: last loss = -0.41336\n",
      "eval step --\n",
      "\n",
      "Step 96: val_rewards = 0.659971595643707\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 97: last loss = -0.36956\n",
      "eval step --\n",
      "\n",
      "Step 97: val_rewards = 0.7578315241166533\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 98: last loss = 0.04229\n",
      "eval step --\n",
      "\n",
      "Step 98: val_rewards = 0.704275318845656\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 99: last loss = 0.06610\n",
      "eval step --\n",
      "\n",
      "Step 99: val_rewards = 0.8719730156847502\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 100: last loss = -0.47979\n",
      "eval step --\n",
      "\n",
      "Step 100: val_rewards = 0.683296593622387\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 101: last loss = -0.55701\n",
      "eval step --\n",
      "\n",
      "Step 101: val_rewards = 0.6778253909266607\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 102: last loss = -0.64144\n",
      "eval step --\n",
      "\n",
      "Step 102: val_rewards = 0.7030095152204693\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 103: last loss = -0.50026\n",
      "eval step --\n",
      "\n",
      "Step 103: val_rewards = 0.638516601656667\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 104: last loss = -0.22761\n",
      "eval step --\n",
      "\n",
      "Step 104: val_rewards = 0.7093814387849141\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 105: last loss = -0.51049\n",
      "eval step --\n",
      "\n",
      "Step 105: val_rewards = 0.7530772027625506\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 106: last loss = -0.39872\n",
      "eval step --\n",
      "\n",
      "Step 106: val_rewards = 0.7342081092829716\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 107: last loss = -0.26140\n",
      "eval step --\n",
      "\n",
      "Step 107: val_rewards = 0.7274030547637147\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 108: last loss = -0.66543\n",
      "eval step --\n",
      "\n",
      "Step 108: val_rewards = 0.7316138408555437\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 109: last loss = -0.51084\n",
      "eval step --\n",
      "\n",
      "Step 109: val_rewards = 0.7031331567464201\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 110: last loss = -0.03468\n",
      "eval step --\n",
      "\n",
      "Step 110: val_rewards = 0.7031366879436877\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 111: last loss = -0.54940\n",
      "eval step --\n",
      "\n",
      "Step 111: val_rewards = 0.7233639139382405\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 112: last loss = -0.26350\n",
      "eval step --\n",
      "\n",
      "Step 112: val_rewards = 0.6637997751739012\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 113: last loss = -0.42232\n",
      "eval step --\n",
      "\n",
      "Step 113: val_rewards = 0.7006554764666009\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 114: last loss = -0.17001\n",
      "eval step --\n",
      "\n",
      "Step 114: val_rewards = 0.7274015776787199\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 115: last loss = -0.55294\n",
      "eval step --\n",
      "\n",
      "Step 115: val_rewards = 0.7005879830802936\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 116: last loss = -0.18187\n",
      "eval step --\n",
      "\n",
      "Step 116: val_rewards = 0.7142135259868033\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 117: last loss = -0.16114\n",
      "eval step --\n",
      "\n",
      "Step 117: val_rewards = 0.7051996114329174\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 118: last loss = -0.11942\n",
      "eval step --\n",
      "\n",
      "Step 118: val_rewards = 0.6996567042806789\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 119: last loss = -0.16262\n",
      "eval step --\n",
      "\n",
      "Step 119: val_rewards = 0.7210800776379649\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 120: last loss = 0.14236\n",
      "eval step --\n",
      "\n",
      "Step 120: val_rewards = 0.7611657649370137\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 121: last loss = -0.29254\n",
      "eval step --\n",
      "\n",
      "Step 121: val_rewards = 0.7273973683531815\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 122: last loss = 0.01062\n",
      "eval step --\n",
      "\n",
      "Step 122: val_rewards = 0.6751460397831062\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 123: last loss = 0.06518\n",
      "eval step --\n",
      "\n",
      "Step 123: val_rewards = 0.7264301816638237\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 124: last loss = -0.47664\n",
      "eval step --\n",
      "\n",
      "Step 124: val_rewards = 0.72950806789331\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 125: last loss = -0.59706\n",
      "eval step --\n",
      "\n",
      "Step 125: val_rewards = 0.736203763373349\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 126: last loss = -0.26602\n",
      "eval step --\n",
      "\n",
      "Step 126: val_rewards = 0.6661148344924251\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 127: last loss = -0.14350\n",
      "eval step --\n",
      "\n",
      "Step 127: val_rewards = 0.6782511876310318\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 128: last loss = -0.29007\n",
      "eval step --\n",
      "\n",
      "Step 128: val_rewards = 0.7013659816036988\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 129: last loss = 0.12562\n",
      "eval step --\n",
      "\n",
      "Step 129: val_rewards = 0.6946546500161213\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 130: last loss = -0.11819\n",
      "eval step --\n",
      "\n",
      "Step 130: val_rewards = 0.6648089810715404\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 131: last loss = -0.02475\n",
      "eval step --\n",
      "\n",
      "Step 131: val_rewards = 0.697646479137315\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 132: last loss = -0.23897\n",
      "eval step --\n",
      "\n",
      "Step 132: val_rewards = 0.6849548970755376\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 133: last loss = -0.24071\n",
      "eval step --\n",
      "\n",
      "Step 133: val_rewards = 0.6669343910362596\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 134: last loss = -0.76607\n",
      "eval step --\n",
      "\n",
      "Step 134: val_rewards = 0.699012983805035\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 135: last loss = -0.20396\n",
      "eval step --\n",
      "\n",
      "Step 135: val_rewards = 0.6554010138777199\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 136: last loss = -0.20923\n",
      "eval step --\n",
      "\n",
      "Step 136: val_rewards = 0.7048962949647097\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 137: last loss = -0.43314\n",
      "eval step --\n",
      "\n",
      "Step 137: val_rewards = 0.682141313564733\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 138: last loss = 0.01244\n",
      "eval step --\n",
      "\n",
      "Step 138: val_rewards = 0.7045236188343194\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 139: last loss = -0.14558\n",
      "eval step --\n",
      "\n",
      "Step 139: val_rewards = 0.6821408974961025\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 140: last loss = 0.04137\n",
      "eval step --\n",
      "\n",
      "Step 140: val_rewards = 0.6821407132240273\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 141: last loss = -0.09911\n",
      "eval step --\n",
      "\n",
      "Step 141: val_rewards = 0.7288034474323828\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 142: last loss = -0.10717\n",
      "eval step --\n",
      "\n",
      "Step 142: val_rewards = 0.7045234636791224\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 143: last loss = -0.33893\n",
      "eval step --\n",
      "\n",
      "Step 143: val_rewards = 0.7053961364539598\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 144: last loss = -0.46331\n",
      "eval step --\n",
      "\n",
      "Step 144: val_rewards = 0.7398314067664022\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 145: last loss = -0.04233\n",
      "eval step --\n",
      "\n",
      "Step 145: val_rewards = 0.8993621870769214\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 146: last loss = -0.05658\n",
      "eval step --\n",
      "\n",
      "Step 146: val_rewards = 0.7047596015122174\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 147: last loss = -0.00287\n",
      "eval step --\n",
      "\n",
      "Step 147: val_rewards = 0.46185054595831426\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 148: last loss = 0.37191\n",
      "eval step --\n",
      "\n",
      "Step 148: val_rewards = 0.7536664112385812\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 149: last loss = 0.03060\n",
      "eval step --\n",
      "\n",
      "Step 149: val_rewards = 0.8118790191018601\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 150: last loss = -0.42287\n",
      "eval step --\n",
      "\n",
      "Step 150: val_rewards = 0.6795859036025932\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 151: last loss = -0.20174\n",
      "eval step --\n",
      "\n",
      "Step 151: val_rewards = 0.6467956821263072\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 152: last loss = -0.56328\n",
      "eval step --\n",
      "\n",
      "Step 152: val_rewards = 0.9317588772751557\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 153: last loss = -0.13269\n",
      "eval step --\n",
      "\n",
      "Step 153: val_rewards = 0.618165508315192\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 154: last loss = -0.22191\n",
      "eval step --\n",
      "\n",
      "Step 154: val_rewards = 0.7918364427389399\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 155: last loss = -0.00456\n",
      "eval step --\n",
      "\n",
      "Step 155: val_rewards = 0.6617278476255476\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 156: last loss = -0.65593\n",
      "eval step --\n",
      "\n",
      "Step 156: val_rewards = 0.6223323086380724\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 157: last loss = -0.00608\n",
      "eval step --\n",
      "\n",
      "Step 157: val_rewards = 0.5097513019673936\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 158: last loss = -0.50798\n",
      "eval step --\n",
      "\n",
      "Step 158: val_rewards = 0.4011155348573396\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 159: last loss = -0.08304\n",
      "eval step --\n",
      "\n",
      "Step 159: val_rewards = 1.1097323827810797\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 160: last loss = -0.06346\n",
      "eval step --\n",
      "\n",
      "Step 160: val_rewards = 0.7145423644451956\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 161: last loss = -0.67094\n",
      "eval step --\n",
      "\n",
      "Step 161: val_rewards = 0.7765906105997465\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 162: last loss = 0.00869\n",
      "eval step --\n",
      "\n",
      "Step 162: val_rewards = 0.742681258808457\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 163: last loss = 0.08773\n",
      "eval step --\n",
      "\n",
      "Step 163: val_rewards = 0.9997698134960061\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 164: last loss = -0.05357\n",
      "eval step --\n",
      "\n",
      "Step 164: val_rewards = 0.5919241862722348\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 165: last loss = -0.49018\n",
      "eval step --\n",
      "\n",
      "Step 165: val_rewards = 0.8042667982004786\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 166: last loss = -0.10694\n",
      "eval step --\n",
      "\n",
      "Step 166: val_rewards = 0.7061911582053703\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 167: last loss = -0.16435\n",
      "eval step --\n",
      "\n",
      "Step 167: val_rewards = 0.6160532822854056\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 168: last loss = -0.07235\n",
      "eval step --\n",
      "\n",
      "Step 168: val_rewards = 0.5299500140047582\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 169: last loss = -0.37264\n",
      "eval step --\n",
      "\n",
      "Step 169: val_rewards = 0.6145742913405623\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 170: last loss = 0.09587\n",
      "eval step --\n",
      "\n",
      "Step 170: val_rewards = 0.7384926843888026\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 171: last loss = -0.45035\n",
      "eval step --\n",
      "\n",
      "Step 171: val_rewards = 0.9010469093357656\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 172: last loss = -0.14476\n",
      "eval step --\n",
      "\n",
      "Step 172: val_rewards = 0.6840539143663394\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 173: last loss = -0.18774\n",
      "eval step --\n",
      "\n",
      "Step 173: val_rewards = 1.0104207799930862\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 174: last loss = -0.67870\n",
      "eval step --\n",
      "\n",
      "Step 174: val_rewards = 0.4015849098969481\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 175: last loss = -0.17461\n",
      "eval step --\n",
      "\n",
      "Step 175: val_rewards = 0.9061461694899761\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 176: last loss = -0.11118\n",
      "eval step --\n",
      "\n",
      "Step 176: val_rewards = 0.5580987691373039\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 177: last loss = -0.14154\n",
      "eval step --\n",
      "\n",
      "Step 177: val_rewards = 0.887492351638759\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 178: last loss = 0.04732\n",
      "eval step --\n",
      "\n",
      "Step 178: val_rewards = 0.7014310661849475\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 179: last loss = -0.00226\n",
      "eval step --\n",
      "\n",
      "Step 179: val_rewards = 0.6029402478760038\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 180: last loss = -0.50123\n",
      "eval step --\n",
      "\n",
      "Step 180: val_rewards = 0.5803546290891368\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 181: last loss = -0.32715\n",
      "eval step --\n",
      "\n",
      "Step 181: val_rewards = 0.653243842396923\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 182: last loss = -0.39227\n",
      "eval step --\n",
      "\n",
      "Step 182: val_rewards = 0.8893005110515135\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 183: last loss = -0.16595\n",
      "eval step --\n",
      "\n",
      "Step 183: val_rewards = 1.006278664009075\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 184: last loss = -0.59076\n",
      "eval step --\n",
      "\n",
      "Step 184: val_rewards = 0.9316645515667428\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 185: last loss = -0.54388\n",
      "eval step --\n",
      "\n",
      "Step 185: val_rewards = 0.6468791841865091\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 186: last loss = -0.20900\n",
      "eval step --\n",
      "\n",
      "Step 186: val_rewards = 0.8254980604609903\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 187: last loss = -0.38002\n",
      "eval step --\n",
      "\n",
      "Step 187: val_rewards = 0.8416791300538237\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 188: last loss = -0.04683\n",
      "eval step --\n",
      "\n",
      "Step 188: val_rewards = 0.479872548158365\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 189: last loss = -0.18625\n",
      "eval step --\n",
      "\n",
      "Step 189: val_rewards = 0.6376249370577061\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 190: last loss = -0.41373\n",
      "eval step --\n",
      "\n",
      "Step 190: val_rewards = 0.9835995192375848\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 191: last loss = -0.06931\n",
      "eval step --\n",
      "\n",
      "Step 191: val_rewards = 0.8979421807162843\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 192: last loss = -0.39636\n",
      "eval step --\n",
      "\n",
      "Step 192: val_rewards = 0.7147006878136323\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 193: last loss = -0.63518\n",
      "eval step --\n",
      "\n",
      "Step 193: val_rewards = 0.7106696552493664\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 194: last loss = -0.55750\n",
      "eval step --\n",
      "\n",
      "Step 194: val_rewards = 0.961943582389985\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 195: last loss = -0.11407\n",
      "eval step --\n",
      "\n",
      "Step 195: val_rewards = 0.5983242645274669\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 196: last loss = -0.28775\n",
      "eval step --\n",
      "\n",
      "Step 196: val_rewards = 0.8704499423579307\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 197: last loss = -0.41368\n",
      "eval step --\n",
      "\n",
      "Step 197: val_rewards = 0.7055033632721733\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 198: last loss = -0.06981\n",
      "eval step --\n",
      "\n",
      "Step 198: val_rewards = 0.4364904805639775\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 199: last loss = -0.61455\n",
      "eval step --\n",
      "\n",
      "Step 199: val_rewards = 0.716545723883022\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 200: last loss = -0.99587\n",
      "eval step --\n",
      "\n",
      "Step 200: val_rewards = 0.8620423365813685\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 201: last loss = -0.06245\n",
      "eval step --\n",
      "\n",
      "Step 201: val_rewards = 0.719569545589196\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 202: last loss = 0.02321\n",
      "eval step --\n",
      "\n",
      "Step 202: val_rewards = 0.8367481490736484\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 203: last loss = -0.09351\n",
      "eval step --\n",
      "\n",
      "Step 203: val_rewards = 1.1009739135550107\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 204: last loss = 0.04483\n",
      "eval step --\n",
      "\n",
      "Step 204: val_rewards = 0.8901424928799563\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 205: last loss = -0.14197\n",
      "eval step --\n",
      "\n",
      "Step 205: val_rewards = 0.5899044557789261\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 206: last loss = 0.11259\n",
      "eval step --\n",
      "\n",
      "Step 206: val_rewards = 0.5067622233104565\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 207: last loss = 0.21007\n",
      "eval step --\n",
      "\n",
      "Step 207: val_rewards = 0.7821980101999187\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 208: last loss = -1.00035\n",
      "eval step --\n",
      "\n",
      "Step 208: val_rewards = 0.7071059343626483\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 209: last loss = -0.96032\n",
      "eval step --\n",
      "\n",
      "Step 209: val_rewards = 0.9127117600366575\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 210: last loss = -0.58454\n",
      "eval step --\n",
      "\n",
      "Step 210: val_rewards = 0.5165638968560575\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 211: last loss = -0.23030\n",
      "eval step --\n",
      "\n",
      "Step 211: val_rewards = 0.5393618706698718\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 212: last loss = -0.52981\n",
      "eval step --\n",
      "\n",
      "Step 212: val_rewards = 0.6461106441199559\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 213: last loss = -0.49157\n",
      "eval step --\n",
      "\n",
      "Step 213: val_rewards = 0.9086294416495599\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 214: last loss = 0.00789\n",
      "eval step --\n",
      "\n",
      "Step 214: val_rewards = 0.7712221135593609\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 215: last loss = -0.27957\n",
      "eval step --\n",
      "\n",
      "Step 215: val_rewards = 0.7884177760213661\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 216: last loss = -0.49642\n",
      "eval step --\n",
      "\n",
      "Step 216: val_rewards = 0.8223274434626126\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 217: last loss = -0.80264\n",
      "eval step --\n",
      "\n",
      "Step 217: val_rewards = 0.657735318136413\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 218: last loss = -0.02343\n",
      "eval step --\n",
      "\n",
      "Step 218: val_rewards = 0.7864772953532093\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 219: last loss = -0.67737\n",
      "eval step --\n",
      "\n",
      "Step 219: val_rewards = 0.7315238873394547\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 220: last loss = -1.29381\n",
      "eval step --\n",
      "\n",
      "Step 220: val_rewards = 0.3757823640931076\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 221: last loss = 0.11269\n",
      "eval step --\n",
      "\n",
      "Step 221: val_rewards = 0.5296050869155561\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 222: last loss = -0.11599\n",
      "eval step --\n",
      "\n",
      "Step 222: val_rewards = 0.6619351968937469\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 223: last loss = 0.29277\n",
      "eval step --\n",
      "\n",
      "Step 223: val_rewards = 0.6468012589165942\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 224: last loss = -0.59810\n",
      "eval step --\n",
      "\n",
      "Step 224: val_rewards = 0.6074871628732433\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 225: last loss = -0.46038\n",
      "eval step --\n",
      "\n",
      "Step 225: val_rewards = 1.0314863967503076\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 226: last loss = -0.22315\n",
      "eval step --\n",
      "\n",
      "Step 226: val_rewards = 0.6157645214351917\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 227: last loss = 0.16529\n",
      "eval step --\n",
      "\n",
      "Step 227: val_rewards = 0.6183791808605585\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 228: last loss = -0.54779\n",
      "eval step --\n",
      "\n",
      "Step 228: val_rewards = 0.6233315454927146\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 229: last loss = 0.28886\n",
      "eval step --\n",
      "\n",
      "Step 229: val_rewards = 0.6523634079638466\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 230: last loss = 0.26728\n",
      "eval step --\n",
      "\n",
      "Step 230: val_rewards = 1.0182288409218054\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 231: last loss = -0.95736\n",
      "eval step --\n",
      "\n",
      "Step 231: val_rewards = 0.4732966111450772\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 232: last loss = -0.31151\n",
      "eval step --\n",
      "\n",
      "Step 232: val_rewards = 0.6148889954403464\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 233: last loss = -0.19705\n",
      "eval step --\n",
      "\n",
      "Step 233: val_rewards = 0.5130867945892866\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 234: last loss = -0.09829\n",
      "eval step --\n",
      "\n",
      "Step 234: val_rewards = 0.49137790102821327\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 235: last loss = -0.06828\n",
      "eval step --\n",
      "\n",
      "Step 235: val_rewards = 0.968932074967712\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 236: last loss = -0.28698\n",
      "eval step --\n",
      "\n",
      "Step 236: val_rewards = 0.5187544605755583\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 237: last loss = -0.88140\n",
      "eval step --\n",
      "\n",
      "Step 237: val_rewards = 0.6852247279366914\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 238: last loss = -0.15088\n",
      "eval step --\n",
      "\n",
      "Step 238: val_rewards = 0.8239512331172912\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 239: last loss = -0.07011\n",
      "eval step --\n",
      "\n",
      "Step 239: val_rewards = 0.7655644017115978\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 240: last loss = -0.25091\n",
      "eval step --\n",
      "\n",
      "Step 240: val_rewards = 0.7434675827947728\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 241: last loss = -1.05079\n",
      "eval step --\n",
      "\n",
      "Step 241: val_rewards = 0.7700448878289207\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 242: last loss = -0.53570\n",
      "eval step --\n",
      "\n",
      "Step 242: val_rewards = 0.6862536196517101\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 243: last loss = -0.22719\n",
      "eval step --\n",
      "\n",
      "Step 243: val_rewards = 0.6596563627477466\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 244: last loss = -0.24433\n",
      "eval step --\n",
      "\n",
      "Step 244: val_rewards = 0.6128190529238597\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 245: last loss = 0.17052\n",
      "eval step --\n",
      "\n",
      "Step 245: val_rewards = 0.6631808685221245\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 246: last loss = -0.71906\n",
      "eval step --\n",
      "\n",
      "Step 246: val_rewards = 0.582952277326457\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 247: last loss = 0.10515\n",
      "eval step --\n",
      "\n",
      "Step 247: val_rewards = 0.489919391001493\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 248: last loss = -0.19827\n",
      "eval step --\n",
      "\n",
      "Step 248: val_rewards = 0.5468987516605739\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 249: last loss = -0.30095\n",
      "eval step --\n",
      "\n",
      "Step 249: val_rewards = 0.4229270061218941\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 250: last loss = -0.81618\n",
      "eval step --\n",
      "\n",
      "Step 250: val_rewards = 0.7636121994448236\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 251: last loss = -0.04456\n",
      "eval step --\n",
      "\n",
      "Step 251: val_rewards = 0.6358858433236037\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 252: last loss = -0.16111\n",
      "eval step --\n",
      "\n",
      "Step 252: val_rewards = 0.6026987880322592\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 253: last loss = -0.23946\n",
      "eval step --\n",
      "\n",
      "Step 253: val_rewards = 0.8269248344832824\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 254: last loss = -0.27954\n",
      "eval step --\n",
      "\n",
      "Step 254: val_rewards = 0.810802649978078\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 255: last loss = 0.10234\n",
      "eval step --\n",
      "\n",
      "Step 255: val_rewards = 1.1640172868849572\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 256: last loss = -1.33647\n",
      "eval step --\n",
      "\n",
      "Step 256: val_rewards = 0.7877296530265758\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 257: last loss = 0.17160\n",
      "eval step --\n",
      "\n",
      "Step 257: val_rewards = 0.39220919196268983\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 258: last loss = -0.16810\n",
      "eval step --\n",
      "\n",
      "Step 258: val_rewards = 0.7842636460710423\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 259: last loss = 0.65489\n",
      "eval step --\n",
      "\n",
      "Step 259: val_rewards = 0.6954286069873556\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 260: last loss = -0.24597\n",
      "eval step --\n",
      "\n",
      "Step 260: val_rewards = 1.001135890694372\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 261: last loss = -0.74830\n",
      "eval step --\n",
      "\n",
      "Step 261: val_rewards = 0.8007280328114853\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 262: last loss = -0.58800\n",
      "eval step --\n",
      "\n",
      "Step 262: val_rewards = 0.7552168765845658\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 263: last loss = 0.25501\n",
      "eval step --\n",
      "\n",
      "Step 263: val_rewards = 0.7071468969874074\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 264: last loss = -0.10643\n",
      "eval step --\n",
      "\n",
      "Step 264: val_rewards = 0.7269518702143787\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 265: last loss = -0.31176\n",
      "eval step --\n",
      "\n",
      "Step 265: val_rewards = 0.5980140764805735\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 266: last loss = -0.19100\n",
      "eval step --\n",
      "\n",
      "Step 266: val_rewards = 0.5387541206179508\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 267: last loss = 0.05019\n",
      "eval step --\n",
      "\n",
      "Step 267: val_rewards = 0.46704007306839335\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 268: last loss = -0.82570\n",
      "eval step --\n",
      "\n",
      "Step 268: val_rewards = 0.790310633278936\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 269: last loss = 0.34308\n",
      "eval step --\n",
      "\n",
      "Step 269: val_rewards = 0.8403268524040153\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 270: last loss = -0.32261\n",
      "eval step --\n",
      "\n",
      "Step 270: val_rewards = 0.7738820182266097\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 271: last loss = -0.09670\n",
      "eval step --\n",
      "\n",
      "Step 271: val_rewards = 0.7968324922620482\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 272: last loss = -0.39242\n",
      "eval step --\n",
      "\n",
      "Step 272: val_rewards = 1.1540969229594313\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 273: last loss = 0.08116\n",
      "eval step --\n",
      "\n",
      "Step 273: val_rewards = 0.6911323400204599\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 274: last loss = -0.95464\n",
      "eval step --\n",
      "\n",
      "Step 274: val_rewards = 0.5823358946659477\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 275: last loss = -0.12806\n",
      "eval step --\n",
      "\n",
      "Step 275: val_rewards = 0.8153706877143108\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 276: last loss = 0.00646\n",
      "eval step --\n",
      "\n",
      "Step 276: val_rewards = 0.7546709794111189\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 277: last loss = -0.91355\n",
      "eval step --\n",
      "\n",
      "Step 277: val_rewards = 0.6434727142224782\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 278: last loss = 0.12884\n",
      "eval step --\n",
      "\n",
      "Step 278: val_rewards = 0.49420841147736727\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 279: last loss = -0.62917\n",
      "eval step --\n",
      "\n",
      "Step 279: val_rewards = 0.5816793903862447\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 280: last loss = -0.09526\n",
      "eval step --\n",
      "\n",
      "Step 280: val_rewards = 0.43644216660036134\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 281: last loss = -0.58597\n",
      "eval step --\n",
      "\n",
      "Step 281: val_rewards = 0.6910861832102506\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 282: last loss = -0.17904\n",
      "eval step --\n",
      "\n",
      "Step 282: val_rewards = 0.535002552293868\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 283: last loss = -0.01712\n",
      "eval step --\n",
      "\n",
      "Step 283: val_rewards = 0.8253506640924874\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 284: last loss = 0.09364\n",
      "eval step --\n",
      "\n",
      "Step 284: val_rewards = 0.6098644199924208\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 285: last loss = -0.46443\n",
      "eval step --\n",
      "\n",
      "Step 285: val_rewards = 1.0303836344577442\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 286: last loss = -0.03876\n",
      "eval step --\n",
      "\n",
      "Step 286: val_rewards = 0.5409265730552797\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 287: last loss = 0.05927\n",
      "eval step --\n",
      "\n",
      "Step 287: val_rewards = 0.6116172108721547\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 288: last loss = -0.82034\n",
      "eval step --\n",
      "\n",
      "Step 288: val_rewards = 0.5838271661384855\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 289: last loss = -0.82205\n",
      "eval step --\n",
      "\n",
      "Step 289: val_rewards = 0.4595057168113259\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 290: last loss = 0.02520\n",
      "eval step --\n",
      "\n",
      "Step 290: val_rewards = 0.6381858182970236\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 291: last loss = -0.23517\n",
      "eval step --\n",
      "\n",
      "Step 291: val_rewards = 0.6178200013353548\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 292: last loss = -1.00388\n",
      "eval step --\n",
      "\n",
      "Step 292: val_rewards = 0.8339455553689451\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 293: last loss = -0.13224\n",
      "eval step --\n",
      "\n",
      "Step 293: val_rewards = 0.5709385703351305\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 294: last loss = -0.05558\n",
      "eval step --\n",
      "\n",
      "Step 294: val_rewards = 0.6963321906795554\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 295: last loss = -0.44215\n",
      "eval step --\n",
      "\n",
      "Step 295: val_rewards = 0.6682659673431031\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 296: last loss = -0.09265\n",
      "eval step --\n",
      "\n",
      "Step 296: val_rewards = 0.6731676912397752\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 297: last loss = -0.41459\n",
      "eval step --\n",
      "\n",
      "Step 297: val_rewards = 0.5955325865902156\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 298: last loss = 0.14047\n",
      "eval step --\n",
      "\n",
      "Step 298: val_rewards = 0.8454958682604722\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 299: last loss = -1.38942\n",
      "eval step --\n",
      "\n",
      "Step 299: val_rewards = 0.8601844243696951\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 300: last loss = 0.23204\n",
      "eval step --\n",
      "\n",
      "Step 300: val_rewards = 0.8113256209702764\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 301: last loss = 0.10811\n",
      "eval step --\n",
      "\n",
      "Step 301: val_rewards = 0.7709491030611372\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 302: last loss = 0.04246\n",
      "eval step --\n",
      "\n",
      "Step 302: val_rewards = 0.4296776870242948\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 303: last loss = -0.15210\n",
      "eval step --\n",
      "\n",
      "Step 303: val_rewards = 0.7665721580089084\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 304: last loss = -0.47140\n",
      "eval step --\n",
      "\n",
      "Step 304: val_rewards = 0.7580584161453455\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 305: last loss = -0.00856\n",
      "eval step --\n",
      "\n",
      "Step 305: val_rewards = 0.5351735447405623\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 306: last loss = -0.23776\n",
      "eval step --\n",
      "\n",
      "Step 306: val_rewards = 0.8843975353211778\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 307: last loss = -0.10261\n",
      "eval step --\n",
      "\n",
      "Step 307: val_rewards = 0.6807917623092277\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 308: last loss = -0.25499\n",
      "eval step --\n",
      "\n",
      "Step 308: val_rewards = 0.686369142831097\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 309: last loss = -0.93008\n",
      "eval step --\n",
      "\n",
      "Step 309: val_rewards = 0.5823706596056049\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 310: last loss = -0.70608\n",
      "eval step --\n",
      "\n",
      "Step 310: val_rewards = 0.42431862401807285\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 311: last loss = -1.11766\n",
      "eval step --\n",
      "\n",
      "Step 311: val_rewards = 0.7234380641848202\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 312: last loss = -0.57748\n",
      "eval step --\n",
      "\n",
      "Step 312: val_rewards = 0.704601516168482\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 313: last loss = -0.34441\n",
      "eval step --\n",
      "\n",
      "Step 313: val_rewards = 0.5667558750357344\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 314: last loss = 0.01883\n",
      "eval step --\n",
      "\n",
      "Step 314: val_rewards = 0.7627340416861037\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 315: last loss = 0.10544\n",
      "eval step --\n",
      "\n",
      "Step 315: val_rewards = 0.7837922978191942\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 316: last loss = -0.55310\n",
      "eval step --\n",
      "\n",
      "Step 316: val_rewards = 0.5728296685418351\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 317: last loss = -0.37722\n",
      "eval step --\n",
      "\n",
      "Step 317: val_rewards = 0.7234485600560062\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 318: last loss = -0.65929\n",
      "eval step --\n",
      "\n",
      "Step 318: val_rewards = 0.7936235407270715\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 319: last loss = -0.04260\n",
      "eval step --\n",
      "\n",
      "Step 319: val_rewards = 0.6899194893934227\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 320: last loss = -0.83714\n",
      "eval step --\n",
      "\n",
      "Step 320: val_rewards = 1.1236231332180546\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 321: last loss = 0.06525\n",
      "eval step --\n",
      "\n",
      "Step 321: val_rewards = 1.1029675132192005\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 322: last loss = 0.00035\n",
      "eval step --\n",
      "\n",
      "Step 322: val_rewards = 0.5921668011605069\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 323: last loss = -0.58693\n",
      "eval step --\n",
      "\n",
      "Step 323: val_rewards = 0.6437677352570259\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 324: last loss = 0.29111\n",
      "eval step --\n",
      "\n",
      "Step 324: val_rewards = 0.7499965731123228\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 325: last loss = 0.27007\n",
      "eval step --\n",
      "\n",
      "Step 325: val_rewards = 0.5636096627411807\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 326: last loss = -0.02292\n",
      "eval step --\n",
      "\n",
      "Step 326: val_rewards = 0.748059734760402\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 327: last loss = -0.12693\n",
      "eval step --\n",
      "\n",
      "Step 327: val_rewards = 0.7133997792582898\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 328: last loss = -0.09523\n",
      "eval step --\n",
      "\n",
      "Step 328: val_rewards = 0.7953559473807496\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 329: last loss = -0.12579\n",
      "eval step --\n",
      "\n",
      "Step 329: val_rewards = 0.6205033474544479\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 330: last loss = -0.33767\n",
      "eval step --\n",
      "\n",
      "Step 330: val_rewards = 0.958060800805653\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 331: last loss = 0.00228\n",
      "eval step --\n",
      "\n",
      "Step 331: val_rewards = 0.9445354903912424\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 332: last loss = -0.68041\n",
      "eval step --\n",
      "\n",
      "Step 332: val_rewards = 0.8806274362736595\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 333: last loss = -0.19522\n",
      "eval step --\n",
      "\n",
      "Step 333: val_rewards = 0.6869611527568682\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 334: last loss = -0.15913\n",
      "eval step --\n",
      "\n",
      "Step 334: val_rewards = 0.8037380953683351\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 335: last loss = -0.22427\n",
      "eval step --\n",
      "\n",
      "Step 335: val_rewards = 0.9112555850584515\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 336: last loss = -0.93653\n",
      "eval step --\n",
      "\n",
      "Step 336: val_rewards = 0.50504489440922\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 337: last loss = 0.05126\n",
      "eval step --\n",
      "\n",
      "Step 337: val_rewards = 0.8225854082051735\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 338: last loss = -0.22222\n",
      "eval step --\n",
      "\n",
      "Step 338: val_rewards = 0.8316374162439463\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 339: last loss = -0.12589\n",
      "eval step --\n",
      "\n",
      "Step 339: val_rewards = 0.5369323830137511\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 340: last loss = -0.90606\n",
      "eval step --\n",
      "\n",
      "Step 340: val_rewards = 0.5341054471112097\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 341: last loss = -0.90808\n",
      "eval step --\n",
      "\n",
      "Step 341: val_rewards = 0.531798086806328\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 342: last loss = -0.68181\n",
      "eval step --\n",
      "\n",
      "Step 342: val_rewards = 0.8362666258460989\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 343: last loss = -0.37822\n",
      "eval step --\n",
      "\n",
      "Step 343: val_rewards = 0.5643547550247795\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 344: last loss = 0.03852\n",
      "eval step --\n",
      "\n",
      "Step 344: val_rewards = 0.5361175218847672\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 345: last loss = 0.03147\n",
      "eval step --\n",
      "\n",
      "Step 345: val_rewards = 0.8198964725378761\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 346: last loss = -0.49062\n",
      "eval step --\n",
      "\n",
      "Step 346: val_rewards = 0.6456478735040947\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 347: last loss = -0.00591\n",
      "eval step --\n",
      "\n",
      "Step 347: val_rewards = 0.7733044327706511\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 348: last loss = -0.62926\n",
      "eval step --\n",
      "\n",
      "Step 348: val_rewards = 0.7336320800521733\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 349: last loss = 0.01379\n",
      "eval step --\n",
      "\n",
      "Step 349: val_rewards = 1.1251026513493045\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 350: last loss = -0.11211\n",
      "eval step --\n",
      "\n",
      "Step 350: val_rewards = 0.7154796551232857\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 351: last loss = -0.00244\n",
      "eval step --\n",
      "\n",
      "Step 351: val_rewards = 0.5375997566038798\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 352: last loss = -0.49948\n",
      "eval step --\n",
      "\n",
      "Step 352: val_rewards = 0.6569153481934319\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 353: last loss = -0.12247\n",
      "eval step --\n",
      "\n",
      "Step 353: val_rewards = 0.5545600694151519\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 354: last loss = -0.09983\n",
      "eval step --\n",
      "\n",
      "Step 354: val_rewards = 0.9879029561148089\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 355: last loss = -0.58365\n",
      "eval step --\n",
      "\n",
      "Step 355: val_rewards = 0.9729382938122586\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 356: last loss = -0.56709\n",
      "eval step --\n",
      "\n",
      "Step 356: val_rewards = 0.8019162970267376\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 357: last loss = -0.16499\n",
      "eval step --\n",
      "\n",
      "Step 357: val_rewards = 1.0518984429800304\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 358: last loss = 0.06709\n",
      "eval step --\n",
      "\n",
      "Step 358: val_rewards = 0.6899386406792677\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 359: last loss = -0.63157\n",
      "eval step --\n",
      "\n",
      "Step 359: val_rewards = 0.7573197035747437\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 360: last loss = -0.16548\n",
      "eval step --\n",
      "\n",
      "Step 360: val_rewards = 1.169046651997124\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 361: last loss = 0.22748\n",
      "eval step --\n",
      "\n",
      "Step 361: val_rewards = 0.5301201642398734\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 362: last loss = -0.89543\n",
      "eval step --\n",
      "\n",
      "Step 362: val_rewards = 0.5621702966126184\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 363: last loss = 0.04693\n",
      "eval step --\n",
      "\n",
      "Step 363: val_rewards = 0.8630583001783175\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 364: last loss = -0.29418\n",
      "eval step --\n",
      "\n",
      "Step 364: val_rewards = 0.660252162488704\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 365: last loss = -0.12659\n",
      "eval step --\n",
      "\n",
      "Step 365: val_rewards = 0.6902692720660506\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 366: last loss = -0.24738\n",
      "eval step --\n",
      "\n",
      "Step 366: val_rewards = 0.490079335438449\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 367: last loss = -0.17709\n",
      "eval step --\n",
      "\n",
      "Step 367: val_rewards = 1.063009513981237\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 368: last loss = -0.76425\n",
      "eval step --\n",
      "\n",
      "Step 368: val_rewards = 0.8401244291695804\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 369: last loss = 0.23659\n",
      "eval step --\n",
      "\n",
      "Step 369: val_rewards = 0.6093878084873524\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 370: last loss = -0.65420\n",
      "eval step --\n",
      "\n",
      "Step 370: val_rewards = 0.5414884342608249\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 371: last loss = -0.39050\n",
      "eval step --\n",
      "\n",
      "Step 371: val_rewards = 0.6734420144748193\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 372: last loss = -0.61863\n",
      "eval step --\n",
      "\n",
      "Step 372: val_rewards = 0.572582744310484\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 373: last loss = -0.25627\n",
      "eval step --\n",
      "\n",
      "Step 373: val_rewards = 0.728153142912193\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 374: last loss = -0.13434\n",
      "eval step --\n",
      "\n",
      "Step 374: val_rewards = 0.7054296283987442\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 375: last loss = -0.87046\n",
      "eval step --\n",
      "\n",
      "Step 375: val_rewards = 0.7394096394402294\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 376: last loss = -0.53542\n",
      "eval step --\n",
      "\n",
      "Step 376: val_rewards = 0.8302356772261776\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 377: last loss = 0.15799\n",
      "eval step --\n",
      "\n",
      "Step 377: val_rewards = 0.4620122889336688\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 378: last loss = -0.41877\n",
      "eval step --\n",
      "\n",
      "Step 378: val_rewards = 0.8705924423159173\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 379: last loss = 0.08983\n",
      "eval step --\n",
      "\n",
      "Step 379: val_rewards = 0.5281065083905706\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 380: last loss = 0.12410\n",
      "eval step --\n",
      "\n",
      "Step 380: val_rewards = 0.4585052899408451\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 381: last loss = -0.96158\n",
      "eval step --\n",
      "\n",
      "Step 381: val_rewards = 0.6129096265383014\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 382: last loss = -0.49682\n",
      "eval step --\n",
      "\n",
      "Step 382: val_rewards = 0.8008814959368193\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 383: last loss = -0.30984\n",
      "eval step --\n",
      "\n",
      "Step 383: val_rewards = 0.5955829534831218\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 384: last loss = -0.74067\n",
      "eval step --\n",
      "\n",
      "Step 384: val_rewards = 0.316739696277413\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 385: last loss = -0.17849\n",
      "eval step --\n",
      "\n",
      "Step 385: val_rewards = 0.7687527847306398\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 386: last loss = 0.23435\n",
      "eval step --\n",
      "\n",
      "Step 386: val_rewards = 0.44941618717828785\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 387: last loss = -0.23559\n",
      "eval step --\n",
      "\n",
      "Step 387: val_rewards = 0.5994491714208109\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 388: last loss = -0.09358\n",
      "eval step --\n",
      "\n",
      "Step 388: val_rewards = 0.809663339182635\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 389: last loss = 0.04192\n",
      "eval step --\n",
      "\n",
      "Step 389: val_rewards = 0.46933455398399243\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 390: last loss = -0.56276\n",
      "eval step --\n",
      "\n",
      "Step 390: val_rewards = 0.737428032851231\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 391: last loss = -0.45187\n",
      "eval step --\n",
      "\n",
      "Step 391: val_rewards = 0.8397215638204037\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 392: last loss = -0.07445\n",
      "eval step --\n",
      "\n",
      "Step 392: val_rewards = 0.969655578214727\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 393: last loss = -0.13883\n",
      "eval step --\n",
      "\n",
      "Step 393: val_rewards = 0.8325143854022526\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 394: last loss = -0.13107\n",
      "eval step --\n",
      "\n",
      "Step 394: val_rewards = 0.6672758711485394\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 395: last loss = -0.04289\n",
      "eval step --\n",
      "\n",
      "Step 395: val_rewards = 0.6110263779971357\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 396: last loss = -0.97699\n",
      "eval step --\n",
      "\n",
      "Step 396: val_rewards = 0.412075688471354\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 397: last loss = -0.69564\n",
      "eval step --\n",
      "\n",
      "Step 397: val_rewards = 0.663205925609455\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 398: last loss = -0.09792\n",
      "eval step --\n",
      "\n",
      "Step 398: val_rewards = 0.7673343766659024\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 399: last loss = -0.48911\n",
      "eval step --\n",
      "\n",
      "Step 399: val_rewards = 0.6683363579860081\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 400: last loss = 0.10055\n",
      "eval step --\n",
      "\n",
      "Step 400: val_rewards = 0.42891913152654\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 401: last loss = -0.68878\n",
      "eval step --\n",
      "\n",
      "Step 401: val_rewards = 0.6113820392073566\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 402: last loss = -0.14682\n",
      "eval step --\n",
      "\n",
      "Step 402: val_rewards = 0.9305939718716159\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 403: last loss = -0.32374\n",
      "eval step --\n",
      "\n",
      "Step 403: val_rewards = 0.6385716935514367\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 404: last loss = 0.04050\n",
      "eval step --\n",
      "\n",
      "Step 404: val_rewards = 0.44363735011062716\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 405: last loss = -0.30106\n",
      "eval step --\n",
      "\n",
      "Step 405: val_rewards = 0.6653640083703619\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 406: last loss = -0.08834\n",
      "eval step --\n",
      "\n",
      "Step 406: val_rewards = 0.723996091141598\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 407: last loss = -0.38289\n",
      "eval step --\n",
      "\n",
      "Step 407: val_rewards = 0.915277720974235\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 408: last loss = -0.07502\n",
      "eval step --\n",
      "\n",
      "Step 408: val_rewards = 0.6338942037022318\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 409: last loss = -0.12113\n",
      "eval step --\n",
      "\n",
      "Step 409: val_rewards = 0.8890098834584232\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 410: last loss = -1.26848\n",
      "eval step --\n",
      "\n",
      "Step 410: val_rewards = 0.7535076992565964\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 411: last loss = -0.08185\n",
      "eval step --\n",
      "\n",
      "Step 411: val_rewards = 0.7293232824370579\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 412: last loss = 0.06478\n",
      "eval step --\n",
      "\n",
      "Step 412: val_rewards = 0.9468323092895851\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 413: last loss = -0.20583\n",
      "eval step --\n",
      "\n",
      "Step 413: val_rewards = 0.610346531455028\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 414: last loss = 0.20498\n",
      "eval step --\n",
      "\n",
      "Step 414: val_rewards = 0.6581453103187326\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 415: last loss = -0.31052\n",
      "eval step --\n",
      "\n",
      "Step 415: val_rewards = 0.4951442910629567\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 416: last loss = -0.95035\n",
      "eval step --\n",
      "\n",
      "Step 416: val_rewards = 0.6008447719420923\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 417: last loss = -0.81537\n",
      "eval step --\n",
      "\n",
      "Step 417: val_rewards = 0.849500500551077\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 418: last loss = -0.06013\n",
      "eval step --\n",
      "\n",
      "Step 418: val_rewards = 0.9456548039562633\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 419: last loss = -0.61803\n",
      "eval step --\n",
      "\n",
      "Step 419: val_rewards = 0.7415381714483082\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 420: last loss = -0.92549\n",
      "eval step --\n",
      "\n",
      "Step 420: val_rewards = 0.8362073806930869\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 421: last loss = -0.12185\n",
      "eval step --\n",
      "\n",
      "Step 421: val_rewards = 0.8221717291869751\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 422: last loss = -0.06905\n",
      "eval step --\n",
      "\n",
      "Step 422: val_rewards = 0.3849453602408532\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 423: last loss = -0.76223\n",
      "eval step --\n",
      "\n",
      "Step 423: val_rewards = 0.8079779121892996\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 424: last loss = -0.79989\n",
      "eval step --\n",
      "\n",
      "Step 424: val_rewards = 0.668708594794881\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 425: last loss = 0.05540\n",
      "eval step --\n",
      "\n",
      "Step 425: val_rewards = 0.7789130837190634\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 426: last loss = -0.49816\n",
      "eval step --\n",
      "\n",
      "Step 426: val_rewards = 0.6617525555812594\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 427: last loss = 0.20436\n",
      "eval step --\n",
      "\n",
      "Step 427: val_rewards = 0.606268926410032\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 428: last loss = -0.84672\n",
      "eval step --\n",
      "\n",
      "Step 428: val_rewards = 0.7042713706603007\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 429: last loss = -0.42639\n",
      "eval step --\n",
      "\n",
      "Step 429: val_rewards = 0.6256364493833307\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 430: last loss = -0.39496\n",
      "eval step --\n",
      "\n",
      "Step 430: val_rewards = 0.5942867086793082\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 431: last loss = -0.64781\n",
      "eval step --\n",
      "\n",
      "Step 431: val_rewards = 0.8645053603718342\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 432: last loss = -0.27095\n",
      "eval step --\n",
      "\n",
      "Step 432: val_rewards = 0.2885750613071197\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 433: last loss = -0.86831\n",
      "eval step --\n",
      "\n",
      "Step 433: val_rewards = 0.587712472466092\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 434: last loss = -0.10865\n",
      "eval step --\n",
      "\n",
      "Step 434: val_rewards = 0.5557093398271935\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 435: last loss = 0.05198\n",
      "eval step --\n",
      "\n",
      "Step 435: val_rewards = 0.62401571997679\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 436: last loss = -0.07646\n",
      "eval step --\n",
      "\n",
      "Step 436: val_rewards = 0.7345208081120522\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 437: last loss = -0.19466\n",
      "eval step --\n",
      "\n",
      "Step 437: val_rewards = 0.8397441352255909\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 438: last loss = 0.43394\n",
      "eval step --\n",
      "\n",
      "Step 438: val_rewards = 0.6897807247958967\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 439: last loss = 0.24172\n",
      "eval step --\n",
      "\n",
      "Step 439: val_rewards = 0.7071472839199353\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 440: last loss = -0.12520\n",
      "eval step --\n",
      "\n",
      "Step 440: val_rewards = 0.5444383622047289\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 441: last loss = -0.12933\n",
      "eval step --\n",
      "\n",
      "Step 441: val_rewards = 0.6748227666234771\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 442: last loss = -0.56334\n",
      "eval step --\n",
      "\n",
      "Step 442: val_rewards = 0.5122734439226196\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 443: last loss = 0.09575\n",
      "eval step --\n",
      "\n",
      "Step 443: val_rewards = 0.40676267053108667\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 444: last loss = 0.22905\n",
      "eval step --\n",
      "\n",
      "Step 444: val_rewards = 0.701748727466614\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 445: last loss = -0.58670\n",
      "eval step --\n",
      "\n",
      "Step 445: val_rewards = 1.1192233817968273\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 446: last loss = -0.30467\n",
      "eval step --\n",
      "\n",
      "Step 446: val_rewards = 0.7480095070493292\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 447: last loss = 0.03942\n",
      "eval step --\n",
      "\n",
      "Step 447: val_rewards = 0.6926509715768339\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 448: last loss = 0.27736\n",
      "eval step --\n",
      "\n",
      "Step 448: val_rewards = 0.8804629223898904\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 449: last loss = -0.51495\n",
      "eval step --\n",
      "\n",
      "Step 449: val_rewards = 0.7218104125915737\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 450: last loss = -0.25687\n",
      "eval step --\n",
      "\n",
      "Step 450: val_rewards = 0.9236012381757005\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 451: last loss = -0.05958\n",
      "eval step --\n",
      "\n",
      "Step 451: val_rewards = 0.5180289717067125\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 452: last loss = -0.20116\n",
      "eval step --\n",
      "\n",
      "Step 452: val_rewards = 1.0143181199696516\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 453: last loss = -0.46450\n",
      "eval step --\n",
      "\n",
      "Step 453: val_rewards = 0.7344626072558672\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 454: last loss = -0.58211\n",
      "eval step --\n",
      "\n",
      "Step 454: val_rewards = 1.0336943142105315\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 455: last loss = -0.57389\n",
      "eval step --\n",
      "\n",
      "Step 455: val_rewards = 0.8017632558497114\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 456: last loss = 0.15870\n",
      "eval step --\n",
      "\n",
      "Step 456: val_rewards = 0.7885932129727702\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 457: last loss = 0.16080\n",
      "eval step --\n",
      "\n",
      "Step 457: val_rewards = 0.4728655621389675\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 458: last loss = 0.09703\n",
      "eval step --\n",
      "\n",
      "Step 458: val_rewards = 1.0754466285720998\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 459: last loss = -0.58885\n",
      "eval step --\n",
      "\n",
      "Step 459: val_rewards = 1.1458359224290093\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 460: last loss = 0.04281\n",
      "eval step --\n",
      "\n",
      "Step 460: val_rewards = 0.5786558226252455\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 461: last loss = -0.72916\n",
      "eval step --\n",
      "\n",
      "Step 461: val_rewards = 0.48556394476665404\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 462: last loss = -0.50262\n",
      "eval step --\n",
      "\n",
      "Step 462: val_rewards = 1.01688426020518\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 463: last loss = -1.11738\n",
      "eval step --\n",
      "\n",
      "Step 463: val_rewards = 0.5594883636121831\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 464: last loss = -0.11147\n",
      "eval step --\n",
      "\n",
      "Step 464: val_rewards = 0.6701685869731949\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 465: last loss = -0.42180\n",
      "eval step --\n",
      "\n",
      "Step 465: val_rewards = 0.6978248832151852\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 466: last loss = -0.30749\n",
      "eval step --\n",
      "\n",
      "Step 466: val_rewards = 0.8298393053031858\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 467: last loss = 0.59032\n",
      "eval step --\n",
      "\n",
      "Step 467: val_rewards = 0.5662823209820574\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 468: last loss = 0.05489\n",
      "eval step --\n",
      "\n",
      "Step 468: val_rewards = 0.6994434473222059\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 469: last loss = 0.02380\n",
      "eval step --\n",
      "\n",
      "Step 469: val_rewards = 0.6173966955834159\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 470: last loss = 0.00162\n",
      "eval step --\n",
      "\n",
      "Step 470: val_rewards = 0.7818006030846817\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 471: last loss = -0.70482\n",
      "eval step --\n",
      "\n",
      "Step 471: val_rewards = 0.72433669393268\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 472: last loss = -0.64244\n",
      "eval step --\n",
      "\n",
      "Step 472: val_rewards = 0.6038637041972373\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 473: last loss = -0.73572\n",
      "eval step --\n",
      "\n",
      "Step 473: val_rewards = 0.9574392758705489\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 474: last loss = 0.05344\n",
      "eval step --\n",
      "\n",
      "Step 474: val_rewards = 0.9024442089643983\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 475: last loss = -0.02736\n",
      "eval step --\n",
      "\n",
      "Step 475: val_rewards = 0.5365283735048081\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 476: last loss = -0.68561\n",
      "eval step --\n",
      "\n",
      "Step 476: val_rewards = 0.4677680042035469\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 477: last loss = -0.22284\n",
      "eval step --\n",
      "\n",
      "Step 477: val_rewards = 0.8841645106899177\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 478: last loss = -0.73168\n",
      "eval step --\n",
      "\n",
      "Step 478: val_rewards = 0.9437874471118448\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 479: last loss = -1.12889\n",
      "eval step --\n",
      "\n",
      "Step 479: val_rewards = 0.8303029747349494\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 480: last loss = -1.09221\n",
      "eval step --\n",
      "\n",
      "Step 480: val_rewards = 0.9420992814074093\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 481: last loss = -0.50030\n",
      "eval step --\n",
      "\n",
      "Step 481: val_rewards = 0.7958704242939608\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 482: last loss = 0.18052\n",
      "eval step --\n",
      "\n",
      "Step 482: val_rewards = 0.5107336307987573\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 483: last loss = -0.31326\n",
      "eval step --\n",
      "\n",
      "Step 483: val_rewards = 0.529441962519363\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 484: last loss = -0.44480\n",
      "eval step --\n",
      "\n",
      "Step 484: val_rewards = 0.4551023966204675\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 485: last loss = -0.17850\n",
      "eval step --\n",
      "\n",
      "Step 485: val_rewards = 0.43475695498622746\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 486: last loss = 0.02766\n",
      "eval step --\n",
      "\n",
      "Step 486: val_rewards = 1.288674773867713\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 487: last loss = -0.87392\n",
      "eval step --\n",
      "\n",
      "Step 487: val_rewards = 0.5405470639313282\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 488: last loss = 0.00405\n",
      "eval step --\n",
      "\n",
      "Step 488: val_rewards = 0.5551125070507377\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 489: last loss = 0.06326\n",
      "eval step --\n",
      "\n",
      "Step 489: val_rewards = 0.7270451106848923\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 490: last loss = 0.24152\n",
      "eval step --\n",
      "\n",
      "Step 490: val_rewards = 1.0356191577284592\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 491: last loss = -0.06025\n",
      "eval step --\n",
      "\n",
      "Step 491: val_rewards = 0.5868120381538361\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 492: last loss = -0.80700\n",
      "eval step --\n",
      "\n",
      "Step 492: val_rewards = 0.7003839369911152\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 493: last loss = -0.47274\n",
      "eval step --\n",
      "\n",
      "Step 493: val_rewards = 0.7082185860000242\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 494: last loss = -0.04953\n",
      "eval step --\n",
      "\n",
      "Step 494: val_rewards = 0.6456326528796318\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 495: last loss = 0.42560\n",
      "eval step --\n",
      "\n",
      "Step 495: val_rewards = 0.7341735725810856\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 496: last loss = -0.25164\n",
      "eval step --\n",
      "\n",
      "Step 496: val_rewards = 0.9136282514842305\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 497: last loss = -0.26091\n",
      "eval step --\n",
      "\n",
      "Step 497: val_rewards = 0.7384437032007771\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 498: last loss = -0.04504\n",
      "eval step --\n",
      "\n",
      "Step 498: val_rewards = 0.7900768928003228\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 499: last loss = -1.12026\n",
      "eval step --\n",
      "\n",
      "Step 499: val_rewards = 0.616161332291467\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 500: last loss = -0.50352\n",
      "eval step --\n",
      "\n",
      "Step 500: val_rewards = 1.0270347613473854\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 501: last loss = -0.25791\n",
      "eval step --\n",
      "\n",
      "Step 501: val_rewards = 0.9870474580139559\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 502: last loss = -0.30142\n",
      "eval step --\n",
      "\n",
      "Step 502: val_rewards = 0.7228794432274399\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 503: last loss = -0.87217\n",
      "eval step --\n",
      "\n",
      "Step 503: val_rewards = 0.8363930474793526\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 504: last loss = 0.18339\n",
      "eval step --\n",
      "\n",
      "Step 504: val_rewards = 0.6361699067138799\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 505: last loss = -0.85458\n",
      "eval step --\n",
      "\n",
      "Step 505: val_rewards = 0.7718697273771206\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 506: last loss = 0.10118\n",
      "eval step --\n",
      "\n",
      "Step 506: val_rewards = 0.8698186316208874\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 507: last loss = 0.13418\n",
      "eval step --\n",
      "\n",
      "Step 507: val_rewards = 0.9542262700046843\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 508: last loss = -0.54159\n",
      "eval step --\n",
      "\n",
      "Step 508: val_rewards = 0.7633609649916805\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 509: last loss = 0.26822\n",
      "eval step --\n",
      "\n",
      "Step 509: val_rewards = 0.7097307463688801\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 510: last loss = -0.06000\n",
      "eval step --\n",
      "\n",
      "Step 510: val_rewards = 0.809363256695705\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 511: last loss = -0.13407\n",
      "eval step --\n",
      "\n",
      "Step 511: val_rewards = 0.6914561093112913\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 512: last loss = -0.06438\n",
      "eval step --\n",
      "\n",
      "Step 512: val_rewards = 0.47204119580032755\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 513: last loss = 0.00552\n",
      "eval step --\n",
      "\n",
      "Step 513: val_rewards = 0.6386658884614514\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 514: last loss = 0.31221\n",
      "eval step --\n",
      "\n",
      "Step 514: val_rewards = 0.4391981896056499\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 515: last loss = -0.45473\n",
      "eval step --\n",
      "\n",
      "Step 515: val_rewards = 0.5228347208154354\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 516: last loss = -0.46200\n",
      "eval step --\n",
      "\n",
      "Step 516: val_rewards = 0.8564462100429088\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 517: last loss = -0.61167\n",
      "eval step --\n",
      "\n",
      "Step 517: val_rewards = 1.231990105940118\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 518: last loss = -0.69606\n",
      "eval step --\n",
      "\n",
      "Step 518: val_rewards = 0.711676209158152\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 519: last loss = -0.28168\n",
      "eval step --\n",
      "\n",
      "Step 519: val_rewards = 0.6097426171764906\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 520: last loss = -0.70562\n",
      "eval step --\n",
      "\n",
      "Step 520: val_rewards = 0.6109977341500115\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 521: last loss = -0.11251\n",
      "eval step --\n",
      "\n",
      "Step 521: val_rewards = 0.6538309904894459\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 522: last loss = -0.81612\n",
      "eval step --\n",
      "\n",
      "Step 522: val_rewards = 0.6755116186685908\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 523: last loss = -0.06427\n",
      "eval step --\n",
      "\n",
      "Step 523: val_rewards = 0.6305731444716658\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 524: last loss = -0.54517\n",
      "eval step --\n",
      "\n",
      "Step 524: val_rewards = 0.7003822464820589\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 525: last loss = -0.05573\n",
      "eval step --\n",
      "\n",
      "Step 525: val_rewards = 0.7020932296716685\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 526: last loss = -0.15260\n",
      "eval step --\n",
      "\n",
      "Step 526: val_rewards = 0.7051265019568843\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 527: last loss = -0.36150\n",
      "eval step --\n",
      "\n",
      "Step 527: val_rewards = 0.8474618195927088\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 528: last loss = -0.02223\n",
      "eval step --\n",
      "\n",
      "Step 528: val_rewards = 0.5874906648233019\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 529: last loss = 0.05247\n",
      "eval step --\n",
      "\n",
      "Step 529: val_rewards = 0.7628600289704003\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 530: last loss = -0.59324\n",
      "eval step --\n",
      "\n",
      "Step 530: val_rewards = 0.6971530019493876\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 531: last loss = -0.46805\n",
      "eval step --\n",
      "\n",
      "Step 531: val_rewards = 0.6071494290205268\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 532: last loss = -0.78877\n",
      "eval step --\n",
      "\n",
      "Step 532: val_rewards = 0.5552826634374364\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 533: last loss = -0.07672\n",
      "eval step --\n",
      "\n",
      "Step 533: val_rewards = 0.5233064133588364\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 534: last loss = -0.99707\n",
      "eval step --\n",
      "\n",
      "Step 534: val_rewards = 0.7693744907253416\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 535: last loss = -0.42541\n",
      "eval step --\n",
      "\n",
      "Step 535: val_rewards = 0.6186476982248029\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 536: last loss = -1.12175\n",
      "eval step --\n",
      "\n",
      "Step 536: val_rewards = 1.1404482444944082\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 537: last loss = -0.13667\n",
      "eval step --\n",
      "\n",
      "Step 537: val_rewards = 0.8565590813858883\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 538: last loss = -0.91676\n",
      "eval step --\n",
      "\n",
      "Step 538: val_rewards = 0.6820489731034821\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 539: last loss = 0.05545\n",
      "eval step --\n",
      "\n",
      "Step 539: val_rewards = 0.5873227125964773\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 540: last loss = -0.56791\n",
      "eval step --\n",
      "\n",
      "Step 540: val_rewards = 0.7911509996128485\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 541: last loss = 0.10939\n",
      "eval step --\n",
      "\n",
      "Step 541: val_rewards = 0.4834948393605879\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 542: last loss = 0.00403\n",
      "eval step --\n",
      "\n",
      "Step 542: val_rewards = 0.6598369550126153\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 543: last loss = -0.43495\n",
      "eval step --\n",
      "\n",
      "Step 543: val_rewards = 0.8229817695945876\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 544: last loss = -0.03021\n",
      "eval step --\n",
      "\n",
      "Step 544: val_rewards = 0.8812859358149707\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 545: last loss = 0.08518\n",
      "eval step --\n",
      "\n",
      "Step 545: val_rewards = 0.7691730950669258\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 546: last loss = -0.05061\n",
      "eval step --\n",
      "\n",
      "Step 546: val_rewards = 0.9222748650275501\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 547: last loss = -0.23948\n",
      "eval step --\n",
      "\n",
      "Step 547: val_rewards = 0.5739775747676675\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 548: last loss = -0.22337\n",
      "eval step --\n",
      "\n",
      "Step 548: val_rewards = 0.6780801335312824\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 549: last loss = -0.69142\n",
      "eval step --\n",
      "\n",
      "Step 549: val_rewards = 0.7689045444554609\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 550: last loss = 0.37010\n",
      "eval step --\n",
      "\n",
      "Step 550: val_rewards = 1.0276359930110555\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 551: last loss = -0.02872\n",
      "eval step --\n",
      "\n",
      "Step 551: val_rewards = 0.6123246685500111\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 552: last loss = -0.00404\n",
      "eval step --\n",
      "\n",
      "Step 552: val_rewards = 0.9825120512220484\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 553: last loss = 0.07043\n",
      "eval step --\n",
      "\n",
      "Step 553: val_rewards = 0.57630020873561\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 554: last loss = -0.19710\n",
      "eval step --\n",
      "\n",
      "Step 554: val_rewards = 0.7774198843808228\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 555: last loss = -0.16375\n",
      "eval step --\n",
      "\n",
      "Step 555: val_rewards = 0.8936662738726492\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 556: last loss = 0.17726\n",
      "eval step --\n",
      "\n",
      "Step 556: val_rewards = 0.48429112350754416\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 557: last loss = -0.43430\n",
      "eval step --\n",
      "\n",
      "Step 557: val_rewards = 0.6839548931627419\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 558: last loss = -0.41438\n",
      "eval step --\n",
      "\n",
      "Step 558: val_rewards = 0.800829871204542\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 559: last loss = -0.25868\n",
      "eval step --\n",
      "\n",
      "Step 559: val_rewards = 0.6571669424188782\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 560: last loss = -0.66162\n",
      "eval step --\n",
      "\n",
      "Step 560: val_rewards = 0.8034090738042619\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 561: last loss = -0.15190\n",
      "eval step --\n",
      "\n",
      "Step 561: val_rewards = 0.6679898470724356\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 562: last loss = -0.05426\n",
      "eval step --\n",
      "\n",
      "Step 562: val_rewards = 0.7634984200211892\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 563: last loss = -0.42515\n",
      "eval step --\n",
      "\n",
      "Step 563: val_rewards = 0.5460864335479387\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 564: last loss = 0.05104\n",
      "eval step --\n",
      "\n",
      "Step 564: val_rewards = 0.61546304736955\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 565: last loss = 0.26222\n",
      "eval step --\n",
      "\n",
      "Step 565: val_rewards = 0.7394493752973369\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 566: last loss = -0.11148\n",
      "eval step --\n",
      "\n",
      "Step 566: val_rewards = 0.9285569625925765\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 567: last loss = -1.71536\n",
      "eval step --\n",
      "\n",
      "Step 567: val_rewards = 0.5962728189629766\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 568: last loss = -0.57388\n",
      "eval step --\n",
      "\n",
      "Step 568: val_rewards = 0.7624878861438495\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 569: last loss = -0.67349\n",
      "eval step --\n",
      "\n",
      "Step 569: val_rewards = 0.8933583446292488\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 570: last loss = 0.09992\n",
      "eval step --\n",
      "\n",
      "Step 570: val_rewards = 0.6234969877626164\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 571: last loss = -0.10868\n",
      "eval step --\n",
      "\n",
      "Step 571: val_rewards = 0.9762571796060854\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 572: last loss = -0.00652\n",
      "eval step --\n",
      "\n",
      "Step 572: val_rewards = 0.6138323145687062\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 573: last loss = -0.28399\n",
      "eval step --\n",
      "\n",
      "Step 573: val_rewards = 0.6971129835788195\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 574: last loss = 0.03670\n",
      "eval step --\n",
      "\n",
      "Step 574: val_rewards = 0.8158628422762226\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 575: last loss = -0.07880\n",
      "eval step --\n",
      "\n",
      "Step 575: val_rewards = 0.7908830393520537\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 576: last loss = -0.07183\n",
      "eval step --\n",
      "\n",
      "Step 576: val_rewards = 0.9575673411497532\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 577: last loss = -0.70457\n",
      "eval step --\n",
      "\n",
      "Step 577: val_rewards = 0.4967670261653336\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 578: last loss = -0.31101\n",
      "eval step --\n",
      "\n",
      "Step 578: val_rewards = 0.6201724553337186\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 579: last loss = -0.02301\n",
      "eval step --\n",
      "\n",
      "Step 579: val_rewards = 1.0021138561989889\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 580: last loss = -0.24968\n",
      "eval step --\n",
      "\n",
      "Step 580: val_rewards = 0.7588493487359748\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 581: last loss = 0.02546\n",
      "eval step --\n",
      "\n",
      "Step 581: val_rewards = 0.552690898690487\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 582: last loss = -0.60804\n",
      "eval step --\n",
      "\n",
      "Step 582: val_rewards = 0.7605492444591891\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 583: last loss = -0.61331\n",
      "eval step --\n",
      "\n",
      "Step 583: val_rewards = 0.6852955573523808\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 584: last loss = -0.79904\n",
      "eval step --\n",
      "\n",
      "Step 584: val_rewards = 0.8211639714548222\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 585: last loss = 0.15421\n",
      "eval step --\n",
      "\n",
      "Step 585: val_rewards = 0.8411461562399699\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 586: last loss = -0.56344\n",
      "eval step --\n",
      "\n",
      "Step 586: val_rewards = 0.7216606178611474\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 587: last loss = 0.04894\n",
      "eval step --\n",
      "\n",
      "Step 587: val_rewards = 0.20415064572345817\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 588: last loss = -0.59499\n",
      "eval step --\n",
      "\n",
      "Step 588: val_rewards = 0.16718706030012806\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 589: last loss = -1.02791\n",
      "eval step --\n",
      "\n",
      "Step 589: val_rewards = 0.21945532724605493\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 590: last loss = -0.49780\n",
      "eval step --\n",
      "\n",
      "Step 590: val_rewards = 0.258033397246417\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 591: last loss = 0.03952\n",
      "eval step --\n",
      "\n",
      "Step 591: val_rewards = 0.30785908408732204\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 592: last loss = -0.05212\n",
      "eval step --\n",
      "\n",
      "Step 592: val_rewards = 0.36414352871313765\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 593: last loss = -0.23996\n",
      "eval step --\n",
      "\n",
      "Step 593: val_rewards = 0.3816749830802376\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 594: last loss = 0.05555\n",
      "eval step --\n",
      "\n",
      "Step 594: val_rewards = 0.38043354100890414\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 595: last loss = 0.13121\n",
      "eval step --\n",
      "\n",
      "Step 595: val_rewards = 0.35881397604606674\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 596: last loss = -0.02464\n",
      "eval step --\n",
      "\n",
      "Step 596: val_rewards = 0.4230829794430456\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 597: last loss = 0.16599\n",
      "eval step --\n",
      "\n",
      "Step 597: val_rewards = 0.42308290185143627\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 598: last loss = -1.48209\n",
      "eval step --\n",
      "\n",
      "Step 598: val_rewards = 0.42308299172370967\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 599: last loss = -0.17682\n",
      "eval step --\n",
      "\n",
      "Step 599: val_rewards = 0.4419188593222164\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 600: last loss = -0.18385\n",
      "eval step --\n",
      "\n",
      "Step 600: val_rewards = 0.7892315763983166\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 601: last loss = -0.75755\n",
      "eval step --\n",
      "\n",
      "Step 601: val_rewards = 0.7086760548547958\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 602: last loss = -0.01981\n",
      "eval step --\n",
      "\n",
      "Step 602: val_rewards = 0.8859782349990706\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 603: last loss = -0.01980\n",
      "eval step --\n",
      "\n",
      "Step 603: val_rewards = 1.0108086030259948\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 604: last loss = -0.05953\n",
      "eval step --\n",
      "\n",
      "Step 604: val_rewards = 0.7176050950616552\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 605: last loss = -0.50586\n",
      "eval step --\n",
      "\n",
      "Step 605: val_rewards = 0.5439887690810564\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 606: last loss = -0.05662\n",
      "eval step --\n",
      "\n",
      "Step 606: val_rewards = 0.9964815366150456\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 607: last loss = -0.17024\n",
      "eval step --\n",
      "\n",
      "Step 607: val_rewards = 0.6949108451082359\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 608: last loss = -0.60192\n",
      "eval step --\n",
      "\n",
      "Step 608: val_rewards = 0.6658029387343052\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 609: last loss = -0.50638\n",
      "eval step --\n",
      "\n",
      "Step 609: val_rewards = 1.0686632539853256\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 610: last loss = -0.14754\n",
      "eval step --\n",
      "\n",
      "Step 610: val_rewards = 0.5243899645168584\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 611: last loss = -0.35759\n",
      "eval step --\n",
      "\n",
      "Step 611: val_rewards = 0.6067360519389817\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 612: last loss = 0.16851\n",
      "eval step --\n",
      "\n",
      "Step 612: val_rewards = 0.8763924784307061\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 613: last loss = 0.04539\n",
      "eval step --\n",
      "\n",
      "Step 613: val_rewards = 0.6179379097300226\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 614: last loss = -0.01407\n",
      "eval step --\n",
      "\n",
      "Step 614: val_rewards = 0.663835322462062\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 615: last loss = -0.13209\n",
      "eval step --\n",
      "\n",
      "Step 615: val_rewards = 0.9335676242178778\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 616: last loss = -0.73819\n",
      "eval step --\n",
      "\n",
      "Step 616: val_rewards = 0.6476407488209213\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 617: last loss = -0.11692\n",
      "eval step --\n",
      "\n",
      "Step 617: val_rewards = 0.9224560605096613\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 618: last loss = -0.72141\n",
      "eval step --\n",
      "\n",
      "Step 618: val_rewards = 0.8793752590783136\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 619: last loss = -0.63939\n",
      "eval step --\n",
      "\n",
      "Step 619: val_rewards = 0.8001080247506541\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 620: last loss = -0.40614\n",
      "eval step --\n",
      "\n",
      "Step 620: val_rewards = 0.9700999363243332\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 621: last loss = -0.47937\n",
      "eval step --\n",
      "\n",
      "Step 621: val_rewards = 0.5907305920934882\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 622: last loss = -0.69547\n",
      "eval step --\n",
      "\n",
      "Step 622: val_rewards = 1.4235211356474218\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 623: last loss = 0.03635\n",
      "eval step --\n",
      "\n",
      "Step 623: val_rewards = 0.7020063817479384\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 624: last loss = -0.18193\n",
      "eval step --\n",
      "\n",
      "Step 624: val_rewards = 0.765350886679776\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 625: last loss = -0.69769\n",
      "eval step --\n",
      "\n",
      "Step 625: val_rewards = 0.49783575129305496\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 626: last loss = -0.08174\n",
      "eval step --\n",
      "\n",
      "Step 626: val_rewards = 0.9398709387254266\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 627: last loss = -0.24122\n",
      "eval step --\n",
      "\n",
      "Step 627: val_rewards = 0.7137908178069516\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 628: last loss = -0.35785\n",
      "eval step --\n",
      "\n",
      "Step 628: val_rewards = 0.5400420061514306\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 629: last loss = 0.18500\n",
      "eval step --\n",
      "\n",
      "Step 629: val_rewards = 0.6615201185885725\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 630: last loss = -0.37380\n",
      "eval step --\n",
      "\n",
      "Step 630: val_rewards = 0.8220825036883193\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 631: last loss = -0.47119\n",
      "eval step --\n",
      "\n",
      "Step 631: val_rewards = 0.9534666522463939\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 632: last loss = -0.35249\n",
      "eval step --\n",
      "\n",
      "Step 632: val_rewards = 0.8620415398283463\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 633: last loss = -0.72821\n",
      "eval step --\n",
      "\n",
      "Step 633: val_rewards = 1.1460500787902999\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 634: last loss = 0.23846\n",
      "eval step --\n",
      "\n",
      "Step 634: val_rewards = 0.7123814576597578\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 635: last loss = 0.08329\n",
      "eval step --\n",
      "\n",
      "Step 635: val_rewards = 0.5287070212125348\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 636: last loss = -0.12207\n",
      "eval step --\n",
      "\n",
      "Step 636: val_rewards = 1.2513264543910785\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 637: last loss = -0.76514\n",
      "eval step --\n",
      "\n",
      "Step 637: val_rewards = 1.017473898849153\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 638: last loss = -0.60500\n",
      "eval step --\n",
      "\n",
      "Step 638: val_rewards = 0.6693148153785283\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 639: last loss = -0.66658\n",
      "eval step --\n",
      "\n",
      "Step 639: val_rewards = 0.8314754851535684\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 640: last loss = -0.19705\n",
      "eval step --\n",
      "\n",
      "Step 640: val_rewards = 0.7477778487412781\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 641: last loss = -0.01761\n",
      "eval step --\n",
      "\n",
      "Step 641: val_rewards = 0.604152745064285\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 642: last loss = -0.59484\n",
      "eval step --\n",
      "\n",
      "Step 642: val_rewards = 0.8214711436163188\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 643: last loss = -0.46061\n",
      "eval step --\n",
      "\n",
      "Step 643: val_rewards = 1.2155222040705456\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 644: last loss = -0.25936\n",
      "eval step --\n",
      "\n",
      "Step 644: val_rewards = 1.0555353335927369\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 645: last loss = -0.68132\n",
      "eval step --\n",
      "\n",
      "Step 645: val_rewards = 0.9536202771235933\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 646: last loss = -0.02753\n",
      "eval step --\n",
      "\n",
      "Step 646: val_rewards = 1.3154529655130234\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 647: last loss = -0.09585\n",
      "eval step --\n",
      "\n",
      "Step 647: val_rewards = 0.559680526706729\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 648: last loss = -0.10204\n",
      "eval step --\n",
      "\n",
      "Step 648: val_rewards = 0.7131279032060572\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 649: last loss = -0.08896\n",
      "eval step --\n",
      "\n",
      "Step 649: val_rewards = 0.4968746686436001\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 650: last loss = -0.26817\n",
      "eval step --\n",
      "\n",
      "Step 650: val_rewards = 0.9590533097217409\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 651: last loss = -0.05567\n",
      "eval step --\n",
      "\n",
      "Step 651: val_rewards = 0.6349264372151815\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 652: last loss = -0.32126\n",
      "eval step --\n",
      "\n",
      "Step 652: val_rewards = 0.5545849316117653\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 653: last loss = -0.43708\n",
      "eval step --\n",
      "\n",
      "Step 653: val_rewards = 0.6706834431832632\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 654: last loss = 0.23350\n",
      "eval step --\n",
      "\n",
      "Step 654: val_rewards = 0.5039237577826269\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 655: last loss = -0.67469\n",
      "eval step --\n",
      "\n",
      "Step 655: val_rewards = 0.7585812901077339\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 656: last loss = -0.11220\n",
      "eval step --\n",
      "\n",
      "Step 656: val_rewards = 1.1732107663143652\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 657: last loss = 0.16477\n",
      "eval step --\n",
      "\n",
      "Step 657: val_rewards = 0.8178664959624925\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 658: last loss = 0.05403\n",
      "eval step --\n",
      "\n",
      "Step 658: val_rewards = 0.9897753496196454\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 659: last loss = 0.01666\n",
      "eval step --\n",
      "\n",
      "Step 659: val_rewards = 0.5024595385253154\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 660: last loss = -0.62479\n",
      "eval step --\n",
      "\n",
      "Step 660: val_rewards = 1.0286466219471038\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 661: last loss = -0.76803\n",
      "eval step --\n",
      "\n",
      "Step 661: val_rewards = 0.4874477817798877\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 662: last loss = -0.67326\n",
      "eval step --\n",
      "\n",
      "Step 662: val_rewards = 0.9520678338802498\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 663: last loss = -0.04938\n",
      "eval step --\n",
      "\n",
      "Step 663: val_rewards = 0.6351483159859415\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 664: last loss = -0.04056\n",
      "eval step --\n",
      "\n",
      "Step 664: val_rewards = 0.5730541607637346\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 665: last loss = -0.70770\n",
      "eval step --\n",
      "\n",
      "Step 665: val_rewards = 0.26132538262597804\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 666: last loss = -0.20603\n",
      "eval step --\n",
      "\n",
      "Step 666: val_rewards = 0.4763693299179722\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 667: last loss = -0.35146\n",
      "eval step --\n",
      "\n",
      "Step 667: val_rewards = 0.9424826217390135\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 668: last loss = 0.14524\n",
      "eval step --\n",
      "\n",
      "Step 668: val_rewards = 0.7388152231021872\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 669: last loss = -0.43287\n",
      "eval step --\n",
      "\n",
      "Step 669: val_rewards = 0.5537041861720592\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 670: last loss = -0.15645\n",
      "eval step --\n",
      "\n",
      "Step 670: val_rewards = 0.5119550559849723\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 671: last loss = -0.05481\n",
      "eval step --\n",
      "\n",
      "Step 671: val_rewards = 1.245679806397336\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 672: last loss = -0.07868\n",
      "eval step --\n",
      "\n",
      "Step 672: val_rewards = 0.7466301654522914\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 673: last loss = -0.49023\n",
      "eval step --\n",
      "\n",
      "Step 673: val_rewards = 0.85526791060331\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 674: last loss = -0.30468\n",
      "eval step --\n",
      "\n",
      "Step 674: val_rewards = 0.978464468665815\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 675: last loss = -0.46821\n",
      "eval step --\n",
      "\n",
      "Step 675: val_rewards = 1.0004807087726213\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 676: last loss = -0.02806\n",
      "eval step --\n",
      "\n",
      "Step 676: val_rewards = 0.5675020124524767\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 677: last loss = 0.22677\n",
      "eval step --\n",
      "\n",
      "Step 677: val_rewards = 0.5977082513306028\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 678: last loss = -0.06048\n",
      "eval step --\n",
      "\n",
      "Step 678: val_rewards = 0.7651055652017041\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 679: last loss = -0.15221\n",
      "eval step --\n",
      "\n",
      "Step 679: val_rewards = 1.5609109948065767\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 680: last loss = 0.10343\n",
      "eval step --\n",
      "\n",
      "Step 680: val_rewards = 0.663885712230005\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 681: last loss = 0.21425\n",
      "eval step --\n",
      "\n",
      "Step 681: val_rewards = 0.5378123783424242\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 682: last loss = -0.21255\n",
      "eval step --\n",
      "\n",
      "Step 682: val_rewards = 0.9030165863472187\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 683: last loss = 0.07381\n",
      "eval step --\n",
      "\n",
      "Step 683: val_rewards = 1.0055896138593168\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 684: last loss = -0.11540\n",
      "eval step --\n",
      "\n",
      "Step 684: val_rewards = 0.691924698624903\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 685: last loss = -0.28606\n",
      "eval step --\n",
      "\n",
      "Step 685: val_rewards = 0.6853550368682376\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 686: last loss = 0.01316\n",
      "eval step --\n",
      "\n",
      "Step 686: val_rewards = 0.7781764335375467\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 687: last loss = -0.58671\n",
      "eval step --\n",
      "\n",
      "Step 687: val_rewards = 0.4099806552070796\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 688: last loss = -0.59745\n",
      "eval step --\n",
      "\n",
      "Step 688: val_rewards = 0.69753164662354\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 689: last loss = -0.28001\n",
      "eval step --\n",
      "\n",
      "Step 689: val_rewards = 0.8329119108311067\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 690: last loss = -0.46612\n",
      "eval step --\n",
      "\n",
      "Step 690: val_rewards = 0.6248894989601146\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 691: last loss = -0.03452\n",
      "eval step --\n",
      "\n",
      "Step 691: val_rewards = 0.561047354247087\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 692: last loss = -0.73067\n",
      "eval step --\n",
      "\n",
      "Step 692: val_rewards = 0.7002072091563685\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 693: last loss = -0.59923\n",
      "eval step --\n",
      "\n",
      "Step 693: val_rewards = 0.9306461933601573\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 694: last loss = -0.45443\n",
      "eval step --\n",
      "\n",
      "Step 694: val_rewards = 0.6366833462360785\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 695: last loss = 0.30066\n",
      "eval step --\n",
      "\n",
      "Step 695: val_rewards = 0.6826202768660222\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 696: last loss = -0.57916\n",
      "eval step --\n",
      "\n",
      "Step 696: val_rewards = 0.47897693362474797\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 697: last loss = -0.22566\n",
      "eval step --\n",
      "\n",
      "Step 697: val_rewards = 0.7650751944505909\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 698: last loss = 0.06846\n",
      "eval step --\n",
      "\n",
      "Step 698: val_rewards = 0.574736325304057\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 699: last loss = -0.01965\n",
      "eval step --\n",
      "\n",
      "Step 699: val_rewards = 1.3381264613493555\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 700: last loss = -0.10531\n",
      "eval step --\n",
      "\n",
      "Step 700: val_rewards = 0.6280847191027925\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 701: last loss = -0.44373\n",
      "eval step --\n",
      "\n",
      "Step 701: val_rewards = 1.2417366930365998\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 702: last loss = -0.40960\n",
      "eval step --\n",
      "\n",
      "Step 702: val_rewards = 0.9245239182971615\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 703: last loss = 0.09840\n",
      "eval step --\n",
      "\n",
      "Step 703: val_rewards = 0.672117991127215\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 704: last loss = 0.02706\n",
      "eval step --\n",
      "\n",
      "Step 704: val_rewards = 0.9066581754614749\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 705: last loss = -0.56641\n",
      "eval step --\n",
      "\n",
      "Step 705: val_rewards = 0.8043804075217003\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 706: last loss = -0.15390\n",
      "eval step --\n",
      "\n",
      "Step 706: val_rewards = 0.6029517355026083\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 707: last loss = -0.01837\n",
      "eval step --\n",
      "\n",
      "Step 707: val_rewards = 0.7155631458527114\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 708: last loss = -0.05942\n",
      "eval step --\n",
      "\n",
      "Step 708: val_rewards = 0.9291847129646931\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 709: last loss = -0.11322\n",
      "eval step --\n",
      "\n",
      "Step 709: val_rewards = 1.0220618202722764\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 710: last loss = -0.39403\n",
      "eval step --\n",
      "\n",
      "Step 710: val_rewards = 0.970615328571517\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 711: last loss = -0.45135\n",
      "eval step --\n",
      "\n",
      "Step 711: val_rewards = 0.8575817071792476\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 712: last loss = -0.26687\n",
      "eval step --\n",
      "\n",
      "Step 712: val_rewards = 1.07840745699343\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 713: last loss = -0.08419\n",
      "eval step --\n",
      "\n",
      "Step 713: val_rewards = 0.6033488576383467\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 714: last loss = 0.00452\n",
      "eval step --\n",
      "\n",
      "Step 714: val_rewards = 0.8160348753167734\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 715: last loss = -0.34107\n",
      "eval step --\n",
      "\n",
      "Step 715: val_rewards = 0.8115506530677342\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 716: last loss = -0.23466\n",
      "eval step --\n",
      "\n",
      "Step 716: val_rewards = 0.32602525601072047\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 717: last loss = -0.21555\n",
      "eval step --\n",
      "\n",
      "Step 717: val_rewards = 0.7027751468096602\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 718: last loss = -0.22329\n",
      "eval step --\n",
      "\n",
      "Step 718: val_rewards = 0.7342617671520334\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 719: last loss = -0.11224\n",
      "eval step --\n",
      "\n",
      "Step 719: val_rewards = 0.8084824056189222\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 720: last loss = -0.04657\n",
      "eval step --\n",
      "\n",
      "Step 720: val_rewards = 1.0168160876135683\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 721: last loss = -0.22161\n",
      "eval step --\n",
      "\n",
      "Step 721: val_rewards = 1.0206014284262712\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 722: last loss = -0.68037\n",
      "eval step --\n",
      "\n",
      "Step 722: val_rewards = 0.611357914626937\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 723: last loss = 0.15168\n",
      "eval step --\n",
      "\n",
      "Step 723: val_rewards = 0.8082767349614495\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 724: last loss = -0.04102\n",
      "eval step --\n",
      "\n",
      "Step 724: val_rewards = 0.5295407608211803\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 725: last loss = 0.00752\n",
      "eval step --\n",
      "\n",
      "Step 725: val_rewards = 0.8050110863771612\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 726: last loss = -0.86019\n",
      "eval step --\n",
      "\n",
      "Step 726: val_rewards = 0.5741241626390206\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 727: last loss = -0.03805\n",
      "eval step --\n",
      "\n",
      "Step 727: val_rewards = 0.778600763028783\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 728: last loss = -0.02305\n",
      "eval step --\n",
      "\n",
      "Step 728: val_rewards = 0.719639384092226\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 729: last loss = -0.03176\n",
      "eval step --\n",
      "\n",
      "Step 729: val_rewards = 0.45599319265776656\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 730: last loss = -0.08987\n",
      "eval step --\n",
      "\n",
      "Step 730: val_rewards = 0.7666799211631803\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 731: last loss = -0.10618\n",
      "eval step --\n",
      "\n",
      "Step 731: val_rewards = 1.0175528172768749\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 732: last loss = 0.19190\n",
      "eval step --\n",
      "\n",
      "Step 732: val_rewards = 0.7759455906738627\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 733: last loss = -0.83480\n",
      "eval step --\n",
      "\n",
      "Step 733: val_rewards = 0.7486460676905845\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 734: last loss = -0.36026\n",
      "eval step --\n",
      "\n",
      "Step 734: val_rewards = 0.8449456836581185\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 735: last loss = -0.04311\n",
      "eval step --\n",
      "\n",
      "Step 735: val_rewards = 0.6132168046226852\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 736: last loss = -0.21724\n",
      "eval step --\n",
      "\n",
      "Step 736: val_rewards = 0.752643162506797\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 737: last loss = -0.17483\n",
      "eval step --\n",
      "\n",
      "Step 737: val_rewards = 0.5439769460848857\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 738: last loss = -0.13822\n",
      "eval step --\n",
      "\n",
      "Step 738: val_rewards = 0.8483444630427288\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 739: last loss = -0.82658\n",
      "eval step --\n",
      "\n",
      "Step 739: val_rewards = 0.7810346632740138\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 740: last loss = -0.67444\n",
      "eval step --\n",
      "\n",
      "Step 740: val_rewards = 0.7869597342285634\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 741: last loss = -0.00778\n",
      "eval step --\n",
      "\n",
      "Step 741: val_rewards = 0.513417045674448\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 742: last loss = 0.15076\n",
      "eval step --\n",
      "\n",
      "Step 742: val_rewards = 0.6703874472343944\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 743: last loss = -0.98077\n",
      "eval step --\n",
      "\n",
      "Step 743: val_rewards = 1.0013863633641242\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 744: last loss = -0.15881\n",
      "eval step --\n",
      "\n",
      "Step 744: val_rewards = 0.9228220878119406\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 745: last loss = -0.68897\n",
      "eval step --\n",
      "\n",
      "Step 745: val_rewards = 0.5245568409409098\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 746: last loss = -0.28648\n",
      "eval step --\n",
      "\n",
      "Step 746: val_rewards = 0.5643416797983872\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 747: last loss = -0.39366\n",
      "eval step --\n",
      "\n",
      "Step 747: val_rewards = 0.774693261601833\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 748: last loss = -0.32216\n",
      "eval step --\n",
      "\n",
      "Step 748: val_rewards = 0.7259386937961442\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 749: last loss = 0.02445\n",
      "eval step --\n",
      "\n",
      "Step 749: val_rewards = 0.5396619261618618\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 750: last loss = -1.05864\n",
      "eval step --\n",
      "\n",
      "Step 750: val_rewards = 0.5022816629652885\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 751: last loss = -0.10719\n",
      "eval step --\n",
      "\n",
      "Step 751: val_rewards = 0.7562883272317138\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 752: last loss = -0.14500\n",
      "eval step --\n",
      "\n",
      "Step 752: val_rewards = 0.9750534391308469\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 753: last loss = 0.02306\n",
      "eval step --\n",
      "\n",
      "Step 753: val_rewards = 0.5035516898084674\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 754: last loss = -0.28463\n",
      "eval step --\n",
      "\n",
      "Step 754: val_rewards = 0.7626157040802517\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 755: last loss = -0.08983\n",
      "eval step --\n",
      "\n",
      "Step 755: val_rewards = 0.9136859319222307\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 756: last loss = -0.65413\n",
      "eval step --\n",
      "\n",
      "Step 756: val_rewards = 0.9346826520265075\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 757: last loss = 0.08470\n",
      "eval step --\n",
      "\n",
      "Step 757: val_rewards = 0.43206677362151696\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 758: last loss = -0.09230\n",
      "eval step --\n",
      "\n",
      "Step 758: val_rewards = 0.8835461203407811\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 759: last loss = 0.06433\n",
      "eval step --\n",
      "\n",
      "Step 759: val_rewards = 0.6433451216633496\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 760: last loss = -0.69116\n",
      "eval step --\n",
      "\n",
      "Step 760: val_rewards = 0.7195617126665858\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 761: last loss = 0.28606\n",
      "eval step --\n",
      "\n",
      "Step 761: val_rewards = 0.696567005140498\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 762: last loss = -0.29967\n",
      "eval step --\n",
      "\n",
      "Step 762: val_rewards = 0.8560232747218977\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 763: last loss = -1.08327\n",
      "eval step --\n",
      "\n",
      "Step 763: val_rewards = 0.9960272344708135\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 764: last loss = -0.84957\n",
      "eval step --\n",
      "\n",
      "Step 764: val_rewards = 0.5714251655319132\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 765: last loss = -0.15184\n",
      "eval step --\n",
      "\n",
      "Step 765: val_rewards = 0.7463748427519581\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 766: last loss = -0.00562\n",
      "eval step --\n",
      "\n",
      "Step 766: val_rewards = 0.6758048313411883\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 767: last loss = -0.00361\n",
      "eval step --\n",
      "\n",
      "Step 767: val_rewards = 1.0629692241968673\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 768: last loss = -0.66757\n",
      "eval step --\n",
      "\n",
      "Step 768: val_rewards = 0.6576301371355657\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 769: last loss = -0.43229\n",
      "eval step --\n",
      "\n",
      "Step 769: val_rewards = 0.9100896927932944\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 770: last loss = -0.14916\n",
      "eval step --\n",
      "\n",
      "Step 770: val_rewards = 1.0953363302850534\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 771: last loss = 0.06331\n",
      "eval step --\n",
      "\n",
      "Step 771: val_rewards = 0.6122537747904961\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 772: last loss = -0.72437\n",
      "eval step --\n",
      "\n",
      "Step 772: val_rewards = 0.6113805563561684\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 773: last loss = -0.55404\n",
      "eval step --\n",
      "\n",
      "Step 773: val_rewards = 0.6262087365397127\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 774: last loss = -0.21786\n",
      "eval step --\n",
      "\n",
      "Step 774: val_rewards = 0.7616180689318259\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 775: last loss = -0.43755\n",
      "eval step --\n",
      "\n",
      "Step 775: val_rewards = 0.7982638508712031\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 776: last loss = -0.25972\n",
      "eval step --\n",
      "\n",
      "Step 776: val_rewards = 0.6613237130925548\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 777: last loss = -0.35727\n",
      "eval step --\n",
      "\n",
      "Step 777: val_rewards = 0.7321500775495963\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 778: last loss = -0.07368\n",
      "eval step --\n",
      "\n",
      "Step 778: val_rewards = 0.865999128395619\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 779: last loss = -0.13804\n",
      "eval step --\n",
      "\n",
      "Step 779: val_rewards = 0.8150700943429315\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 780: last loss = -0.36905\n",
      "eval step --\n",
      "\n",
      "Step 780: val_rewards = 0.47316301805901995\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 781: last loss = -0.20583\n",
      "eval step --\n",
      "\n",
      "Step 781: val_rewards = 0.723403161332223\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 782: last loss = 0.10325\n",
      "eval step --\n",
      "\n",
      "Step 782: val_rewards = 1.0904811194063861\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 783: last loss = -0.09011\n",
      "eval step --\n",
      "\n",
      "Step 783: val_rewards = 0.6333768887915623\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 784: last loss = -0.44797\n",
      "eval step --\n",
      "\n",
      "Step 784: val_rewards = 0.45218185842770214\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 785: last loss = -0.56892\n",
      "eval step --\n",
      "\n",
      "Step 785: val_rewards = 0.5369647679313148\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 786: last loss = -0.09541\n",
      "eval step --\n",
      "\n",
      "Step 786: val_rewards = 0.6684120339724126\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 787: last loss = -0.24048\n",
      "eval step --\n",
      "\n",
      "Step 787: val_rewards = 1.0775027368144645\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 788: last loss = -0.16298\n",
      "eval step --\n",
      "\n",
      "Step 788: val_rewards = 0.4255203386412088\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 789: last loss = 0.32032\n",
      "eval step --\n",
      "\n",
      "Step 789: val_rewards = 0.9282498142886726\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 790: last loss = -0.13558\n",
      "eval step --\n",
      "\n",
      "Step 790: val_rewards = 0.591812169765825\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 791: last loss = -0.21707\n",
      "eval step --\n",
      "\n",
      "Step 791: val_rewards = 0.9469419700859635\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 792: last loss = -0.14214\n",
      "eval step --\n",
      "\n",
      "Step 792: val_rewards = 0.894006868679473\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 793: last loss = -0.28401\n",
      "eval step --\n",
      "\n",
      "Step 793: val_rewards = 0.7097930181897442\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 794: last loss = 0.11074\n",
      "eval step --\n",
      "\n",
      "Step 794: val_rewards = 0.7968051544600648\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 795: last loss = 0.04026\n",
      "eval step --\n",
      "\n",
      "Step 795: val_rewards = 0.783632066647726\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 796: last loss = -0.39738\n",
      "eval step --\n",
      "\n",
      "Step 796: val_rewards = 0.9225393570839941\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 797: last loss = -0.67076\n",
      "eval step --\n",
      "\n",
      "Step 797: val_rewards = 0.7289557052360284\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 798: last loss = -0.14215\n",
      "eval step --\n",
      "\n",
      "Step 798: val_rewards = 0.9013628440832215\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 799: last loss = -0.76254\n",
      "eval step --\n",
      "\n",
      "Step 799: val_rewards = 0.8776017944747142\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 800: last loss = -0.01501\n",
      "eval step --\n",
      "\n",
      "Step 800: val_rewards = 0.6242891820324794\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 801: last loss = -0.02896\n",
      "eval step --\n",
      "\n",
      "Step 801: val_rewards = 0.7203757127373713\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 802: last loss = -0.64071\n",
      "eval step --\n",
      "\n",
      "Step 802: val_rewards = 0.6617184512562481\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 803: last loss = 0.10532\n",
      "eval step --\n",
      "\n",
      "Step 803: val_rewards = 0.7546391230937066\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 804: last loss = -0.04922\n",
      "eval step --\n",
      "\n",
      "Step 804: val_rewards = 0.9899394859994621\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 805: last loss = 0.10719\n",
      "eval step --\n",
      "\n",
      "Step 805: val_rewards = 0.6668840439150703\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 806: last loss = -0.22746\n",
      "eval step --\n",
      "\n",
      "Step 806: val_rewards = 1.1202980448236528\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 807: last loss = 0.03293\n",
      "eval step --\n",
      "\n",
      "Step 807: val_rewards = 0.5967604571740613\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 808: last loss = -0.00784\n",
      "eval step --\n",
      "\n",
      "Step 808: val_rewards = 0.7180228612587657\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 809: last loss = -0.20188\n",
      "eval step --\n",
      "\n",
      "Step 809: val_rewards = 0.44843081036415644\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 810: last loss = -0.82126\n",
      "eval step --\n",
      "\n",
      "Step 810: val_rewards = 0.7034314841414855\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 811: last loss = -0.59826\n",
      "eval step --\n",
      "\n",
      "Step 811: val_rewards = 0.7693833467351991\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 812: last loss = -0.28029\n",
      "eval step --\n",
      "\n",
      "Step 812: val_rewards = 0.7548910020384917\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 813: last loss = -0.57741\n",
      "eval step --\n",
      "\n",
      "Step 813: val_rewards = 0.5292353406028716\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 814: last loss = -0.05093\n",
      "eval step --\n",
      "\n",
      "Step 814: val_rewards = 0.46882666155309916\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 815: last loss = -0.71441\n",
      "eval step --\n",
      "\n",
      "Step 815: val_rewards = 0.6020628534174411\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 816: last loss = -0.01960\n",
      "eval step --\n",
      "\n",
      "Step 816: val_rewards = 0.7029146043576564\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 817: last loss = -0.16120\n",
      "eval step --\n",
      "\n",
      "Step 817: val_rewards = 0.6288930703319481\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 818: last loss = -0.17480\n",
      "eval step --\n",
      "\n",
      "Step 818: val_rewards = 0.8072135313758362\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 819: last loss = -0.42938\n",
      "eval step --\n",
      "\n",
      "Step 819: val_rewards = 0.8628115722063149\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 820: last loss = 0.21891\n",
      "eval step --\n",
      "\n",
      "Step 820: val_rewards = 0.4086422225025732\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 821: last loss = -0.47230\n",
      "eval step --\n",
      "\n",
      "Step 821: val_rewards = 0.7027098110758906\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 822: last loss = -0.01519\n",
      "eval step --\n",
      "\n",
      "Step 822: val_rewards = 0.6588292971702383\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 823: last loss = -0.12998\n",
      "eval step --\n",
      "\n",
      "Step 823: val_rewards = 1.290921739960358\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 824: last loss = -0.42613\n",
      "eval step --\n",
      "\n",
      "Step 824: val_rewards = 0.7248911945628733\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 825: last loss = -0.17008\n",
      "eval step --\n",
      "\n",
      "Step 825: val_rewards = 0.4964730145969955\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 826: last loss = 0.05756\n",
      "eval step --\n",
      "\n",
      "Step 826: val_rewards = 0.9024948651419947\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 827: last loss = -0.17322\n",
      "eval step --\n",
      "\n",
      "Step 827: val_rewards = 0.5821557063347802\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 828: last loss = -0.07430\n",
      "eval step --\n",
      "\n",
      "Step 828: val_rewards = 1.1694653417042302\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 829: last loss = -0.11449\n",
      "eval step --\n",
      "\n",
      "Step 829: val_rewards = 0.9604941764249404\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 830: last loss = 0.11683\n",
      "eval step --\n",
      "\n",
      "Step 830: val_rewards = 0.5463507827592702\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 831: last loss = -0.05114\n",
      "eval step --\n",
      "\n",
      "Step 831: val_rewards = 0.6361990592054291\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 832: last loss = -0.53851\n",
      "eval step --\n",
      "\n",
      "Step 832: val_rewards = 0.6510650284512781\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 833: last loss = 0.24427\n",
      "eval step --\n",
      "\n",
      "Step 833: val_rewards = 0.6266663775491381\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 834: last loss = -0.46476\n",
      "eval step --\n",
      "\n",
      "Step 834: val_rewards = 0.9157531292162256\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 835: last loss = -0.12361\n",
      "eval step --\n",
      "\n",
      "Step 835: val_rewards = 0.8882622702902636\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 836: last loss = 0.04401\n",
      "eval step --\n",
      "\n",
      "Step 836: val_rewards = 0.6770572394353763\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 837: last loss = 0.32747\n",
      "eval step --\n",
      "\n",
      "Step 837: val_rewards = 0.5155061758879818\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 838: last loss = 0.04518\n",
      "eval step --\n",
      "\n",
      "Step 838: val_rewards = 0.7555234224362593\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 839: last loss = -0.19590\n",
      "eval step --\n",
      "\n",
      "Step 839: val_rewards = 0.7856643123225632\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 840: last loss = -0.55436\n",
      "eval step --\n",
      "\n",
      "Step 840: val_rewards = 0.8103949731164471\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 841: last loss = -0.21779\n",
      "eval step --\n",
      "\n",
      "Step 841: val_rewards = 0.8592713840228552\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 842: last loss = -0.35992\n",
      "eval step --\n",
      "\n",
      "Step 842: val_rewards = 0.5540854378516965\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 843: last loss = -0.18258\n",
      "eval step --\n",
      "\n",
      "Step 843: val_rewards = 0.6110409019383986\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 844: last loss = -0.70126\n",
      "eval step --\n",
      "\n",
      "Step 844: val_rewards = 0.7329031362541942\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 845: last loss = -1.05391\n",
      "eval step --\n",
      "\n",
      "Step 845: val_rewards = 0.7115892386077267\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 846: last loss = -0.70922\n",
      "eval step --\n",
      "\n",
      "Step 846: val_rewards = 0.778633774002517\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 847: last loss = -0.18484\n",
      "eval step --\n",
      "\n",
      "Step 847: val_rewards = 0.48022956067139677\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 848: last loss = -0.70948\n",
      "eval step --\n",
      "\n",
      "Step 848: val_rewards = 0.7643332068458917\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 849: last loss = 0.17252\n",
      "eval step --\n",
      "\n",
      "Step 849: val_rewards = 0.8329722101204619\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 850: last loss = -0.12110\n",
      "eval step --\n",
      "\n",
      "Step 850: val_rewards = 0.7290738306129767\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 851: last loss = -0.04309\n",
      "eval step --\n",
      "\n",
      "Step 851: val_rewards = 0.8257203366572484\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 852: last loss = -0.34191\n",
      "eval step --\n",
      "\n",
      "Step 852: val_rewards = 0.6310795337724785\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 853: last loss = -0.00974\n",
      "eval step --\n",
      "\n",
      "Step 853: val_rewards = 0.7587314268517776\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 854: last loss = -0.46975\n",
      "eval step --\n",
      "\n",
      "Step 854: val_rewards = 0.76642511236691\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 855: last loss = -0.08080\n",
      "eval step --\n",
      "\n",
      "Step 855: val_rewards = 0.9776191145287814\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 856: last loss = -0.62758\n",
      "eval step --\n",
      "\n",
      "Step 856: val_rewards = 0.6774576877652035\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 857: last loss = -0.08072\n",
      "eval step --\n",
      "\n",
      "Step 857: val_rewards = 0.9276475985569719\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 858: last loss = -0.24164\n",
      "eval step --\n",
      "\n",
      "Step 858: val_rewards = 1.15093314453302\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 859: last loss = -0.30594\n",
      "eval step --\n",
      "\n",
      "Step 859: val_rewards = 0.8107014300525697\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 860: last loss = -0.14507\n",
      "eval step --\n",
      "\n",
      "Step 860: val_rewards = 0.884660019495278\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 861: last loss = -0.41917\n",
      "eval step --\n",
      "\n",
      "Step 861: val_rewards = 0.5942624478545185\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 862: last loss = -0.17925\n",
      "eval step --\n",
      "\n",
      "Step 862: val_rewards = 0.6892673674246739\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 863: last loss = -0.55262\n",
      "eval step --\n",
      "\n",
      "Step 863: val_rewards = 0.49740252904640325\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 864: last loss = -0.84239\n",
      "eval step --\n",
      "\n",
      "Step 864: val_rewards = 0.7676520340104896\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 865: last loss = 0.00230\n",
      "eval step --\n",
      "\n",
      "Step 865: val_rewards = 0.5878380006550433\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 866: last loss = 0.26516\n",
      "eval step --\n",
      "\n",
      "Step 866: val_rewards = 0.9688544423201579\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 867: last loss = -0.73886\n",
      "eval step --\n",
      "\n",
      "Step 867: val_rewards = 0.8830530330477561\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 868: last loss = -0.42167\n",
      "eval step --\n",
      "\n",
      "Step 868: val_rewards = 0.5180937639271987\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 869: last loss = -0.20810\n",
      "eval step --\n",
      "\n",
      "Step 869: val_rewards = 0.7435932278829632\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 870: last loss = -0.10444\n",
      "eval step --\n",
      "\n",
      "Step 870: val_rewards = 0.5826091701242658\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 871: last loss = -0.63718\n",
      "eval step --\n",
      "\n",
      "Step 871: val_rewards = 0.8867279989200614\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 872: last loss = -0.34937\n",
      "eval step --\n",
      "\n",
      "Step 872: val_rewards = 0.5586464150058758\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 873: last loss = 0.24184\n",
      "eval step --\n",
      "\n",
      "Step 873: val_rewards = 0.7794772734756426\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 874: last loss = 0.23150\n",
      "eval step --\n",
      "\n",
      "Step 874: val_rewards = 0.6348777786884705\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 875: last loss = -0.27109\n",
      "eval step --\n",
      "\n",
      "Step 875: val_rewards = 0.5579209973843213\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 876: last loss = 0.10581\n",
      "eval step --\n",
      "\n",
      "Step 876: val_rewards = 1.067569535839941\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 877: last loss = -0.51874\n",
      "eval step --\n",
      "\n",
      "Step 877: val_rewards = 0.37335573792375554\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 878: last loss = -0.13485\n",
      "eval step --\n",
      "\n",
      "Step 878: val_rewards = 0.7129382804137141\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 879: last loss = -0.23508\n",
      "eval step --\n",
      "\n",
      "Step 879: val_rewards = 0.8670683142593337\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 880: last loss = -0.46951\n",
      "eval step --\n",
      "\n",
      "Step 880: val_rewards = 0.7395214654408119\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 881: last loss = -0.15710\n",
      "eval step --\n",
      "\n",
      "Step 881: val_rewards = 0.7821029785332144\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 882: last loss = 0.09990\n",
      "eval step --\n",
      "\n",
      "Step 882: val_rewards = 0.5171655483015929\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 883: last loss = 0.09604\n",
      "eval step --\n",
      "\n",
      "Step 883: val_rewards = 0.5308374654761346\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 884: last loss = -0.53177\n",
      "eval step --\n",
      "\n",
      "Step 884: val_rewards = 1.0064811602915849\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 885: last loss = -0.20331\n",
      "eval step --\n",
      "\n",
      "Step 885: val_rewards = 0.45914892213961345\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 886: last loss = -0.78170\n",
      "eval step --\n",
      "\n",
      "Step 886: val_rewards = 0.5217336650852578\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 887: last loss = -0.07721\n",
      "eval step --\n",
      "\n",
      "Step 887: val_rewards = 0.7744448834773267\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 888: last loss = -0.45469\n",
      "eval step --\n",
      "\n",
      "Step 888: val_rewards = 0.44659354097204296\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 889: last loss = -0.52689\n",
      "eval step --\n",
      "\n",
      "Step 889: val_rewards = 0.7238515265696106\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 890: last loss = -0.71206\n",
      "eval step --\n",
      "\n",
      "Step 890: val_rewards = 0.5375620913270949\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 891: last loss = -0.75621\n",
      "eval step --\n",
      "\n",
      "Step 891: val_rewards = 0.5815733364022864\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 892: last loss = 0.02544\n",
      "eval step --\n",
      "\n",
      "Step 892: val_rewards = 0.5048857135802033\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 893: last loss = -0.28624\n",
      "eval step --\n",
      "\n",
      "Step 893: val_rewards = 0.41904005573553266\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 894: last loss = -0.37956\n",
      "eval step --\n",
      "\n",
      "Step 894: val_rewards = 0.9210390990913865\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 895: last loss = -0.30182\n",
      "eval step --\n",
      "\n",
      "Step 895: val_rewards = 0.5769446319762921\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 896: last loss = -0.60325\n",
      "eval step --\n",
      "\n",
      "Step 896: val_rewards = 0.7432595908754711\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 897: last loss = -0.37253\n",
      "eval step --\n",
      "\n",
      "Step 897: val_rewards = 0.47908586885040455\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 898: last loss = -0.04218\n",
      "eval step --\n",
      "\n",
      "Step 898: val_rewards = 0.3896295085341185\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 899: last loss = -0.45810\n",
      "eval step --\n",
      "\n",
      "Step 899: val_rewards = 0.7627805359291286\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 900: last loss = -0.44145\n",
      "eval step --\n",
      "\n",
      "Step 900: val_rewards = 0.7895314935859601\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 901: last loss = -0.05156\n",
      "eval step --\n",
      "\n",
      "Step 901: val_rewards = 0.6218726592950814\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 902: last loss = -0.68994\n",
      "eval step --\n",
      "\n",
      "Step 902: val_rewards = 0.5149296505447192\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 903: last loss = 0.03210\n",
      "eval step --\n",
      "\n",
      "Step 903: val_rewards = 0.7430639318029522\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 904: last loss = -0.44199\n",
      "eval step --\n",
      "\n",
      "Step 904: val_rewards = 0.7709710442766602\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 905: last loss = -0.13556\n",
      "eval step --\n",
      "\n",
      "Step 905: val_rewards = 0.7574562517651984\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 906: last loss = -0.21173\n",
      "eval step --\n",
      "\n",
      "Step 906: val_rewards = 0.5455000544107512\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 907: last loss = -0.56868\n",
      "eval step --\n",
      "\n",
      "Step 907: val_rewards = 0.6788514110814587\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 908: last loss = -0.23978\n",
      "eval step --\n",
      "\n",
      "Step 908: val_rewards = 0.757417443958908\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 909: last loss = -0.26999\n",
      "eval step --\n",
      "\n",
      "Step 909: val_rewards = 1.2541712356795907\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 910: last loss = -0.39820\n",
      "eval step --\n",
      "\n",
      "Step 910: val_rewards = 0.846814807199471\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 911: last loss = -0.02462\n",
      "eval step --\n",
      "\n",
      "Step 911: val_rewards = 0.9848953434552822\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 912: last loss = -0.35232\n",
      "eval step --\n",
      "\n",
      "Step 912: val_rewards = 0.8617563498789663\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 913: last loss = -0.35767\n",
      "eval step --\n",
      "\n",
      "Step 913: val_rewards = 1.1467442214952133\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 914: last loss = 0.06977\n",
      "eval step --\n",
      "\n",
      "Step 914: val_rewards = 1.0268919854658018\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 915: last loss = -0.16712\n",
      "eval step --\n",
      "\n",
      "Step 915: val_rewards = 0.6433654041160003\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 916: last loss = -0.47427\n",
      "eval step --\n",
      "\n",
      "Step 916: val_rewards = 0.6439792473491507\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 917: last loss = -0.34610\n",
      "eval step --\n",
      "\n",
      "Step 917: val_rewards = 0.7398336785143461\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 918: last loss = -0.56104\n",
      "eval step --\n",
      "\n",
      "Step 918: val_rewards = 0.7518144405526345\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 919: last loss = -0.14183\n",
      "eval step --\n",
      "\n",
      "Step 919: val_rewards = 1.0076083712578678\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 920: last loss = -0.30231\n",
      "eval step --\n",
      "\n",
      "Step 920: val_rewards = 0.4450183829070517\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 921: last loss = -0.10623\n",
      "eval step --\n",
      "\n",
      "Step 921: val_rewards = 0.5035956289268523\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 922: last loss = -1.36458\n",
      "eval step --\n",
      "\n",
      "Step 922: val_rewards = 0.6390012364756804\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 923: last loss = -0.16138\n",
      "eval step --\n",
      "\n",
      "Step 923: val_rewards = 0.8867315158555834\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 924: last loss = -0.15793\n",
      "eval step --\n",
      "\n",
      "Step 924: val_rewards = 1.2313108516330709\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 925: last loss = -0.25137\n",
      "eval step --\n",
      "\n",
      "Step 925: val_rewards = 0.5347906411354946\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 926: last loss = -0.75270\n",
      "eval step --\n",
      "\n",
      "Step 926: val_rewards = 0.9788062381759082\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 927: last loss = -0.78722\n",
      "eval step --\n",
      "\n",
      "Step 927: val_rewards = 0.9457574006065969\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 928: last loss = -0.23669\n",
      "eval step --\n",
      "\n",
      "Step 928: val_rewards = 1.0014230340644033\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 929: last loss = -0.75934\n",
      "eval step --\n",
      "\n",
      "Step 929: val_rewards = 0.9576063223130041\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 930: last loss = -0.11363\n",
      "eval step --\n",
      "\n",
      "Step 930: val_rewards = 0.9514985460504849\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 931: last loss = -0.05554\n",
      "eval step --\n",
      "\n",
      "Step 931: val_rewards = 0.9286948419823711\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 932: last loss = 0.01393\n",
      "eval step --\n",
      "\n",
      "Step 932: val_rewards = 0.873923669205596\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 933: last loss = -0.69055\n",
      "eval step --\n",
      "\n",
      "Step 933: val_rewards = 0.48178034918657103\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 934: last loss = 0.11745\n",
      "eval step --\n",
      "\n",
      "Step 934: val_rewards = 0.7075643413771566\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 935: last loss = -0.22886\n",
      "eval step --\n",
      "\n",
      "Step 935: val_rewards = 0.7070171965751679\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 936: last loss = -0.59034\n",
      "eval step --\n",
      "\n",
      "Step 936: val_rewards = 0.6426674000452002\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 937: last loss = -0.08554\n",
      "eval step --\n",
      "\n",
      "Step 937: val_rewards = 0.8808814540043509\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 938: last loss = -0.54079\n",
      "eval step --\n",
      "\n",
      "Step 938: val_rewards = 0.8593155899673528\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 939: last loss = -0.76972\n",
      "eval step --\n",
      "\n",
      "Step 939: val_rewards = 0.7471453436741982\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 940: last loss = -0.00710\n",
      "eval step --\n",
      "\n",
      "Step 940: val_rewards = 0.7462623355856558\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 941: last loss = -0.49873\n",
      "eval step --\n",
      "\n",
      "Step 941: val_rewards = 1.2440145901175192\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 942: last loss = -0.02188\n",
      "eval step --\n",
      "\n",
      "Step 942: val_rewards = 0.6944303349924175\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 943: last loss = -0.09123\n",
      "eval step --\n",
      "\n",
      "Step 943: val_rewards = 0.758325946267989\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 944: last loss = 0.17313\n",
      "eval step --\n",
      "\n",
      "Step 944: val_rewards = 0.9503972219721946\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 945: last loss = -0.38001\n",
      "eval step --\n",
      "\n",
      "Step 945: val_rewards = 0.8684792479557567\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 946: last loss = 0.03124\n",
      "eval step --\n",
      "\n",
      "Step 946: val_rewards = 0.7372999728137604\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 947: last loss = -0.09042\n",
      "eval step --\n",
      "\n",
      "Step 947: val_rewards = 1.167556079487783\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 948: last loss = -0.29503\n",
      "eval step --\n",
      "\n",
      "Step 948: val_rewards = 0.6733493423163943\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 949: last loss = -0.12562\n",
      "eval step --\n",
      "\n",
      "Step 949: val_rewards = 0.7477767082218062\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 950: last loss = -0.27205\n",
      "eval step --\n",
      "\n",
      "Step 950: val_rewards = 1.1033566509494406\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 951: last loss = -0.16950\n",
      "eval step --\n",
      "\n",
      "Step 951: val_rewards = 0.4622870165463264\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 952: last loss = -0.75268\n",
      "eval step --\n",
      "\n",
      "Step 952: val_rewards = 0.9381482138962851\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 953: last loss = 0.04358\n",
      "eval step --\n",
      "\n",
      "Step 953: val_rewards = 0.7949404199989403\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 954: last loss = -0.08130\n",
      "eval step --\n",
      "\n",
      "Step 954: val_rewards = 0.7644247442763507\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 955: last loss = -1.00887\n",
      "eval step --\n",
      "\n",
      "Step 955: val_rewards = 0.46729699975601263\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 956: last loss = -0.35329\n",
      "eval step --\n",
      "\n",
      "Step 956: val_rewards = 0.2728749351030787\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 957: last loss = 0.29716\n",
      "eval step --\n",
      "\n",
      "Step 957: val_rewards = 0.4736712621412197\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 958: last loss = -0.57956\n",
      "eval step --\n",
      "\n",
      "Step 958: val_rewards = 0.8663245908931254\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 959: last loss = 0.11396\n",
      "eval step --\n",
      "\n",
      "Step 959: val_rewards = 0.7300204646523022\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 960: last loss = -0.54211\n",
      "eval step --\n",
      "\n",
      "Step 960: val_rewards = 0.9807294600452137\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 961: last loss = -0.20379\n",
      "eval step --\n",
      "\n",
      "Step 961: val_rewards = 0.8197156220938665\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 962: last loss = -0.18357\n",
      "eval step --\n",
      "\n",
      "Step 962: val_rewards = 0.4394017324069422\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 963: last loss = 0.01471\n",
      "eval step --\n",
      "\n",
      "Step 963: val_rewards = 0.7125743366434345\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 964: last loss = -0.19299\n",
      "eval step --\n",
      "\n",
      "Step 964: val_rewards = 1.0091058286232293\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 965: last loss = -0.54099\n",
      "eval step --\n",
      "\n",
      "Step 965: val_rewards = 0.7016642588370717\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 966: last loss = -0.45877\n",
      "eval step --\n",
      "\n",
      "Step 966: val_rewards = 0.5684858650192237\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 967: last loss = -0.25772\n",
      "eval step --\n",
      "\n",
      "Step 967: val_rewards = 0.7308444910807304\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 968: last loss = -0.26754\n",
      "eval step --\n",
      "\n",
      "Step 968: val_rewards = 0.7387255420561974\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 969: last loss = 0.07817\n",
      "eval step --\n",
      "\n",
      "Step 969: val_rewards = 0.8759209806287359\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 970: last loss = -0.51233\n",
      "eval step --\n",
      "\n",
      "Step 970: val_rewards = 0.9217957885486732\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 971: last loss = 0.18277\n",
      "eval step --\n",
      "\n",
      "Step 971: val_rewards = 0.4556633329272201\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 972: last loss = -0.11427\n",
      "eval step --\n",
      "\n",
      "Step 972: val_rewards = 0.7054712530810946\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 973: last loss = 0.12874\n",
      "eval step --\n",
      "\n",
      "Step 973: val_rewards = 0.6859739697068201\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 974: last loss = -0.04271\n",
      "eval step --\n",
      "\n",
      "Step 974: val_rewards = 0.9906177604443662\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 975: last loss = -0.40329\n",
      "eval step --\n",
      "\n",
      "Step 975: val_rewards = 0.7223250706307145\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 976: last loss = -0.19510\n",
      "eval step --\n",
      "\n",
      "Step 976: val_rewards = 0.7356757309277586\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 977: last loss = -0.11896\n",
      "eval step --\n",
      "\n",
      "Step 977: val_rewards = 0.7937993758763996\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 978: last loss = -0.05641\n",
      "eval step --\n",
      "\n",
      "Step 978: val_rewards = 1.0789966432814675\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 979: last loss = -0.60441\n",
      "eval step --\n",
      "\n",
      "Step 979: val_rewards = 0.611908935904603\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 980: last loss = -0.03279\n",
      "eval step --\n",
      "\n",
      "Step 980: val_rewards = 0.4638394670541351\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 981: last loss = -0.12368\n",
      "eval step --\n",
      "\n",
      "Step 981: val_rewards = 0.5960584244372849\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 982: last loss = -0.01799\n",
      "eval step --\n",
      "\n",
      "Step 982: val_rewards = 0.9260611773206044\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 983: last loss = 0.03702\n",
      "eval step --\n",
      "\n",
      "Step 983: val_rewards = 0.5751376275874452\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 984: last loss = -0.92621\n",
      "eval step --\n",
      "\n",
      "Step 984: val_rewards = 0.5123036590573506\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 985: last loss = -0.01755\n",
      "eval step --\n",
      "\n",
      "Step 985: val_rewards = 0.7955592613751263\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 986: last loss = -0.60504\n",
      "eval step --\n",
      "\n",
      "Step 986: val_rewards = 0.7433267872574512\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 987: last loss = -0.35141\n",
      "eval step --\n",
      "\n",
      "Step 987: val_rewards = 0.7395963950402443\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 988: last loss = -0.63636\n",
      "eval step --\n",
      "\n",
      "Step 988: val_rewards = 0.7625022687237409\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 989: last loss = -0.26264\n",
      "eval step --\n",
      "\n",
      "Step 989: val_rewards = 0.687643156053996\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 990: last loss = -0.01182\n",
      "eval step --\n",
      "\n",
      "Step 990: val_rewards = 0.9241097750291418\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 991: last loss = -0.07627\n",
      "eval step --\n",
      "\n",
      "Step 991: val_rewards = 0.7760031501523068\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 992: last loss = -0.63843\n",
      "eval step --\n",
      "\n",
      "Step 992: val_rewards = 0.6438459927868425\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 993: last loss = -0.64212\n",
      "eval step --\n",
      "\n",
      "Step 993: val_rewards = 0.8354113330524693\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 994: last loss = -0.24142\n",
      "eval step --\n",
      "\n",
      "Step 994: val_rewards = 0.6650467862398266\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 995: last loss = 0.63610\n",
      "eval step --\n",
      "\n",
      "Step 995: val_rewards = 0.8209771842235648\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 996: last loss = -0.26341\n",
      "eval step --\n",
      "\n",
      "Step 996: val_rewards = 0.6937852370081073\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 997: last loss = -0.56886\n",
      "eval step --\n",
      "\n",
      "Step 997: val_rewards = 0.5364656684355474\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 998: last loss = -0.88171\n",
      "eval step --\n",
      "\n",
      "Step 998: val_rewards = 1.0085452891927034\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 999: last loss = -0.28671\n",
      "eval step --\n",
      "\n",
      "Step 999: val_rewards = 0.4966754561362278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 15:34:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name = f\"v3_training_{tid}\") as run:\n",
    "    params = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"train_step\": train_step,\n",
    "            \"eval_step\": eval_step,\n",
    "            \"metric_function\": 'sharpe',\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \n",
    "            \"symbol_universe\" : symbol_universe,\n",
    "            \"feature_set\" : feature_set,\n",
    "            \"d_model\" : d_model,\n",
    "            \"nheads\" : nheads,\n",
    "            \"num_transformer_layers\" : num_transformer_layers,\n",
    "\n",
    "            \"episode_duration\" : 12,    \n",
    "            \"holding_period\" : 1,\n",
    "            \"train_test_split\" : 0.8,\n",
    "            \"symbol_universe\" : symbol_universe,\n",
    "            \"feature_set\" : feature_set,\n",
    "\n",
    "        }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    portfolio_constructor = PortfolioConstructor(\n",
    "        device = device,\n",
    "        symbol_universe= params['symbol_universe'],\n",
    "        num_features= len(params['feature_set']),\n",
    "        d_model = params['d_model'],\n",
    "        nheads = params['nheads'],\n",
    "        num_transformer_layers = params['num_transformer_layers'],\n",
    "    )\n",
    "\n",
    "    market_env = MarketEnvironment(\n",
    "        device = device,\n",
    "        data_path = data_path,\n",
    "        holding_period = params['holding_period'],\n",
    "        episode_duration = params['episode_duration'],\n",
    "        train_test_split = params['train_test_split'],\n",
    "        symbol_universe = params['symbol_universe'],\n",
    "        feature_set = params['feature_set']\n",
    "        )\n",
    "\n",
    "    portfolio_constructor.cuda()\n",
    "    portfolio_constructor.train()\n",
    "    market_env.reset(mode = \"train\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(portfolio_constructor.parameters(), lr = learning_rate)\n",
    "\n",
    "    max_reward = -1\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        is_end = False\n",
    "        returns = []\n",
    "        tran_costs = []\n",
    "        nlls = []\n",
    "        all_allocations = []\n",
    "\n",
    "        market_env.reset(mode = \"train\", transaction_cost= 1e-7)\n",
    "        state = market_env.get_state()\n",
    "        \n",
    "        while not is_end:\n",
    "            symbol_idx, allocations = portfolio_constructor(state)\n",
    "            state, return_, is_end, tran_cost = market_env.step(allocations)\n",
    "\n",
    "            all_allocations.append(allocations)\n",
    "            returns.append(return_)\n",
    "            tran_costs.append(tran_cost)\n",
    "\n",
    "        sharp_ratio = sharp_ratio_(returns, tran_costs)\n",
    "\n",
    "        loss = -sharp_ratio\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        if (episode + 1) % train_step == 0:\n",
    "\n",
    "                    print(\"-------------------------------------\")\n",
    "                    print(\"training model --\")\n",
    "                    print('Step {}: last loss = {:.5f}\\r'.format(episode, loss), end='')\n",
    "                    print()\n",
    "                    mlflow.log_metric(\"train loss\", f\"{loss:2f}\", step=episode)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count = 0\n",
    "                    \n",
    "        if (episode + 1) % eval_step == 0:\n",
    "            print(\"eval step --\")\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                portfolio_constructor.eval()\n",
    "                reward_val, portfolio_constructor = evaluate(portfolio_constructor, market_env)\n",
    "                portfolio_constructor.train()\n",
    "\n",
    "                print('Step {}: val_rewards = {}'.format(episode, reward_val))\n",
    "                mlflow.log_metric(\"eval_sharpe\", f\"{reward_val:2f}\", step=episode)\n",
    "\n",
    "                if max_reward < reward_val:\n",
    "                    max_reward = reward_val\n",
    "\n",
    "                    print(\"*** found better model ***\")\n",
    "                print()\n",
    "    mlflow.pytorch.log_model(portfolio_constructor, f\"portfolio_constructor_{tid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.1000, 0.1000, 0.0000, 0.0000, 0.1000, 0.1000, 0.1000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.0000,\n",
       "         0.0000, 0.1000], device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000,\n",
       "         0.1000, 0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.1000, 0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.0000,\n",
       "         0.1000, 0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.1000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000, 0.0000,\n",
       "         0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000,\n",
       "         0.0000, 0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000,\n",
       "         0.0000, 0.1000, 0.0000, 0.1000, 0.0000, 0.1000, 0.1000, 0.1000, 0.0000,\n",
       "         0.1000, 0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_allocations[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 15:39:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'portfolio-constructor-v4'.\n",
      "Created version '1' of model 'portfolio-constructor-v4'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7efcd26cc2e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pytorch.log_model(\n",
    "        pytorch_model=portfolio_constructor,\n",
    "        artifact_path = \"portfolio_constructor_{tid}\",\n",
    "        # input_example = market_env.get_random_state(),\n",
    "        registered_model_name=\"portfolio-constructor-v4\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
