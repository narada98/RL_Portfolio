{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import mlflow\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/naradaw/dev/Charles_Schwab/code/RnD/v2/mlflow_experiments/930648686917041142', creation_time=1730715551772, experiment_id='930648686917041142', last_update_time=1730715551772, lifecycle_stage='active', name='/portfolio-contructor-v2', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('file:/home/naradaw/dev/Charles_Schwab/code/RnD/v2/mlflow_experiments')\n",
    "\n",
    "mlflow.set_experiment(\"/portfolio-contructor-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/naradaw/dev/Charles_Schwab/data/symbol_universe/snp_unique_100_2019\", \"rb\") as fp:\n",
    "    symbol_universe = pickle.load(fp)\n",
    "    \n",
    "symbol_universe = symbol_universe[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_path = \"/home/naradaw/dev/Charles_Schwab/data/w_features/v1/2024_10_31/dataset_sqs_2024_10_31_11_18.pkl\"\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape from (symbols, time_steps, seq_len, features) -> (time_steps ,seq_len, symbols, features)\n",
    "\n",
    "data_features = np.array([data[symbol]['features'] for symbol in symbol_universe]).transpose(1,2,0,3)\n",
    "data_returns = np.array([data[symbol]['returns'] for symbol in symbol_universe]).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20, 87)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ten = torch.Tensor(data_features[0]).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/7af8fd7e0c154de0af41e4b932a7134e/portfolio_constructor_2024_11_05_10_10'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SREM(\n",
       "  (compressor): Linear(in_features=87, out_features=88, bias=True)\n",
       "  (TE): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=88, out_features=88, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=88, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=88, bias=True)\n",
       "        (norm1): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srem = loaded_model.SREM\n",
    "srem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAAN(\n",
       "  (W_Q): Linear(in_features=88, out_features=15, bias=True)\n",
       "  (W_K): Linear(in_features=88, out_features=15, bias=True)\n",
       "  (W_V): Linear(in_features=88, out_features=15, bias=True)\n",
       "  (W_O): Linear(in_features=15, out_features=88, bias=True)\n",
       "  (normalizer): LayerNorm((15,), eps=1e-05, elementwise_affine=True)\n",
       "  (scorer): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caan = loaded_model.CAAN\n",
    "caan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4363,  0.4076, -1.0288,  ..., -0.2631,  0.7371, -0.1746],\n",
       "        [-0.4369,  0.4108, -1.0169,  ..., -0.2368,  0.7053, -0.1776],\n",
       "        [-0.4120,  0.3909, -1.0362,  ..., -0.2780,  0.7479, -0.1593],\n",
       "        ...,\n",
       "        [-0.4247,  0.4047, -1.0180,  ..., -0.2414,  0.7050, -0.1666],\n",
       "        [-0.4213,  0.3959, -1.0334,  ..., -0.2722,  0.7426, -0.1676],\n",
       "        [-0.4179,  0.3925, -1.0228,  ..., -0.3036,  0.7723, -0.1651]],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srem_out = srem(sample_ten)\n",
    "srem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.0502, -5.0502, -5.0502, -5.0506, -5.0502, -5.0506, -5.0505, -5.0503,\n",
       "        -5.0501, -5.0503, -5.0505, -5.0507, -5.0501, -5.0503, -5.0502, -5.0502,\n",
       "        -5.0502, -5.0502, -5.0502, -5.0505], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caan_out = caan(srem_out)\n",
    "caan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
