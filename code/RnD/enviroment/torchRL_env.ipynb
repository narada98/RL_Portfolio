{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tqdm \n",
    "import pickle \n",
    "import random \n",
    "import datetime \n",
    "\n",
    "from tensordict import TensorDict, TensorDictBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PortfolioConstructor import PortfolioConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda') \n",
    "    torch.get_default_device()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "      <th>target_</th>\n",
       "      <th>return_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>54.31</td>\n",
       "      <td>54.70</td>\n",
       "      <td>53.84</td>\n",
       "      <td>53.89</td>\n",
       "      <td>138908008.0</td>\n",
       "      <td>295050.0</td>\n",
       "      <td>54.24</td>\n",
       "      <td>55.59</td>\n",
       "      <td>0.031546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>53.15</td>\n",
       "      <td>53.34</td>\n",
       "      <td>52.43</td>\n",
       "      <td>52.85</td>\n",
       "      <td>166028864.0</td>\n",
       "      <td>481648.0</td>\n",
       "      <td>52.89</td>\n",
       "      <td>57.07</td>\n",
       "      <td>0.079849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>52.60</td>\n",
       "      <td>53.18</td>\n",
       "      <td>52.56</td>\n",
       "      <td>53.12</td>\n",
       "      <td>91632552.0</td>\n",
       "      <td>241286.0</td>\n",
       "      <td>52.99</td>\n",
       "      <td>56.98</td>\n",
       "      <td>0.072666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>53.14</td>\n",
       "      <td>53.35</td>\n",
       "      <td>52.94</td>\n",
       "      <td>53.32</td>\n",
       "      <td>79440556.0</td>\n",
       "      <td>154466.0</td>\n",
       "      <td>53.18</td>\n",
       "      <td>56.85</td>\n",
       "      <td>0.066204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>53.41</td>\n",
       "      <td>53.84</td>\n",
       "      <td>53.01</td>\n",
       "      <td>53.82</td>\n",
       "      <td>109082328.0</td>\n",
       "      <td>214155.0</td>\n",
       "      <td>53.56</td>\n",
       "      <td>56.62</td>\n",
       "      <td>0.052025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol   timestamp   open   high    low  close       volume  trade_count  \\\n",
       "0   AAPL  2019-09-12  54.31  54.70  53.84  53.89  138908008.0     295050.0   \n",
       "1   AAPL  2019-09-13  53.15  53.34  52.43  52.85  166028864.0     481648.0   \n",
       "2   AAPL  2019-09-16  52.60  53.18  52.56  53.12   91632552.0     241286.0   \n",
       "3   AAPL  2019-09-17  53.14  53.35  52.94  53.32   79440556.0     154466.0   \n",
       "4   AAPL  2019-09-18  53.41  53.84  53.01  53.82  109082328.0     214155.0   \n",
       "\n",
       "    vwap  target_   return_  \n",
       "0  54.24    55.59  0.031546  \n",
       "1  52.89    57.07  0.079849  \n",
       "2  52.99    56.98  0.072666  \n",
       "3  53.18    56.85  0.066204  \n",
       "4  53.56    56.62  0.052025  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ = pd.read_csv(\"/home/naradaw/dev/Charles_Schwab/data/historical/2024_09_05/dataset_20_2024_09_05_14_49.csv\")\n",
    "dataset_.timestamp = pd.to_datetime(dataset_.timestamp)\n",
    "dataset_.timestamp = dataset_.timestamp.apply(lambda x: x.date())\n",
    "dataset_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2019, 9, 12), datetime.date(2019, 9, 13),\n",
       "       datetime.date(2019, 9, 16), ..., datetime.date(2024, 8, 2),\n",
       "       datetime.date(2024, 8, 5), datetime.date(2024, 8, 6)], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = np.sort(dataset_.timestamp.unique())\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today date : 2023-01-30\n"
     ]
    }
   ],
   "source": [
    "seq_len = (3 * 20)\n",
    "time_horizon = 20\n",
    "\n",
    "today_date = datetime.date(2023, 1, 30)\n",
    "print(f\"today date : {today_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start date : 2022-11-01\n",
      "target date : 2023-02-28\n"
     ]
    }
   ],
   "source": [
    "start_date = dates[np.where(dates==today_date)[0][0] - seq_len]\n",
    "print(f\"start date : {start_date}\")\n",
    "\n",
    "target_date = dates[np.where(dates == today_date)[0][0] + time_horizon]\n",
    "print(f\"target date : {target_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_df = dataset_.loc[(dataset_.timestamp <= today_date) & (dataset_.timestamp > start_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_symbol_uni : \n",
      "['WFC', 'INCY', 'LVS', 'MOH', 'EMR', 'BEN', 'ENPH', 'IFF', 'F', 'EMR', 'BEN', 'VTRS', 'CF', 'INCY', 'CTAS', 'CTRA', 'EXC', 'LKQ', 'ABNB', 'MMC']\n"
     ]
    }
   ],
   "source": [
    "test_symbol_uni = random.choices(list(insample_df.symbol.unique()), k = 20)\n",
    "print(f\"test_symbol_uni : \\n{test_symbol_uni}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_price_sqs = np.array([np.array(insample_df.loc[insample_df.symbol == symbol].close.values) for symbol in test_symbol_uni])\n",
    "target_df = dataset_.loc[(dataset_.symbol.isin(test_symbol_uni) & (dataset_.timestamp == target_date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 44.25,  43.27,  44.41, ...,  43.52,  43.82,  43.98],\n",
       "       [ 77.15,  76.9 ,  77.3 , ...,  86.01,  85.7 ,  83.65],\n",
       "       [ 37.39,  37.07,  39.41, ...,  57.17,  57.71,  56.69],\n",
       "       ...,\n",
       "       [ 49.75,  49.29,  49.35, ...,  55.23,  55.26,  55.51],\n",
       "       [ 94.41,  92.02,  96.09, ..., 109.42, 115.94, 109.48],\n",
       "       [155.12, 155.09, 156.39, ..., 171.89, 168.43, 168.24]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_price_sqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "portfolio_constructor = PortfolioConstructor(\n",
    "    device= device,\n",
    "    symbol_universe = test_symbol_uni,\n",
    "    seq_length = seq_len,\n",
    "    multihead_dim = 2,\n",
    "    num_transformer_layers = 2\n",
    ")\n",
    "\n",
    "historical_price_tensor = torch.from_numpy(historical_price_sqs).to(device).to(torch.float32)\n",
    "portfolio_symbols, allocations = portfolio_constructor(historical_price_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LVS', 'MOH', 'BEN', 'ENPH', 'F', 'BEN', 'VTRS', 'CTAS', 'CTRA', 'MMC'],\n",
       " tensor([0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000, 0.1000, 0.0000, 0.1000,\n",
       "         0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.1001, 0.1000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1000], device='cuda:0', grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_symbols, allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old\n",
    "\n",
    "''' \n",
    "inputs -> symbols and there allocations\n",
    "\n",
    "intermediate -> allocate funds based on total funds and allocation persentage of portfolio\n",
    "\n",
    "outputs -> returns of the portfolio\n",
    "'''\n",
    "\n",
    "def get_returns(symbols, allocations, date):\n",
    "\n",
    "    current_df = dataset_.loc[(dataset_.timestamp == date)&(dataset_.symbol.isin(symbols))].sort_values('symbol')[['symbol','close','return_']]\n",
    "    current_df['allocation'] = allocations\n",
    "    current_df['return_pnl'] = current_df.apply(lambda row : funds * row['allocation']*row['return_'], axis = 1)\n",
    "    portfolio_return = current_df['return_pnl'].sum()/funds\n",
    "    \n",
    "    return portfolio_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New\n",
    "\n",
    "def get_returns(allocations, t_, data):\n",
    "\n",
    "    return (data[t_, : , -2] * data[t_, : , -1] * allocations.detach().cpu().numpy()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" \\nthis functions returns the state (price values when given date)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" \n",
    "this functions returns the state (price values when given date)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "\n",
    "def get_state(date, dates_index, lookback_window, symbol_galaxy):\n",
    "    \n",
    "    start_date = dates_index[np.where(dates_index==date)[0][0] - lookback_window]\n",
    "    insample_df = dataset_.loc[(dataset_.timestamp <= today_date) & (dataset_.timestamp > start_date)]\n",
    "    \n",
    "    state_ = np.array([np.array(insample_df.loc[insample_df.symbol == symbol].close.values) for symbol in symbol_galaxy])\n",
    "\n",
    "    return state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "\n",
    "def get_state(data, t):\n",
    "    price_seq = data[t , : , :-1]\n",
    "    # return_ = data[t , : , -1]\n",
    "\n",
    "    return price_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(data, mode, split_, transaction_cost = 1e-7):\n",
    "\n",
    "    if mode == 'train':\n",
    "        t_ = random.randint(0, split_)\n",
    "        end_t_ = split_\n",
    "    elif mode == 'test':\n",
    "        t_ = split_\n",
    "        end_t_ = len(data)-1\n",
    "\n",
    "    init_state = np.zeros((len(data.shape[1])))\n",
    "\n",
    "    return t_, end_t_, init_state, transaction_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe _step() method should do the following:\\n\\nRead the input keys (such as \"action\") and execute the simulation based on these;\\n\\nRetrieve observations, done state and reward;\\n\\nWrite the set of observation values along with the reward and done state at the corresponding entries in a new TensorDict.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The _step() method should do the following:\n",
    "\n",
    "Read the input keys (such as \"action\") and execute the simulation based on these;\n",
    "\n",
    "Retrieve observations, done state and reward;\n",
    "\n",
    "Write the set of observation values along with the reward and done state at the corresponding entries in a new TensorDict.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "'''\n",
    "def is_end(t_, split_):\n",
    "\n",
    "    return t_ > split_\n",
    "\n",
    "\n",
    "def step(data, t_, allocations, holding_period, split_):\n",
    "\n",
    "    return_ = get_returns(allocations, t_ , data)\n",
    "    t_ = t_ + holding_period\n",
    "    state_ = get_state(data, t_)\n",
    "\n",
    "    return state_, t_, return_, is_end(t_, split_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_end(100, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "to do : consider transaction cost when calculating return\n",
    "'''\n",
    "\n",
    "\n",
    "class MarketEnvironment:\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            data_path,\n",
    "            holding_period,\n",
    "            train_test_split,\n",
    "            symbol_universe,\n",
    "            ):\n",
    "    \n",
    "        self.holding_period = 20 * holding_period #Days\n",
    "        \n",
    "        with open(data_path, 'rb') as f:\n",
    "            self.data_dict = pickle.load(f)\n",
    "        \n",
    "        self.data = (np.array([self.data_dict[symbol] for symbol in symbol_universe])).transpose(1,0,2)\n",
    "        self.split_ = int(self.data.shape[0] * train_test_split)\n",
    "        self.t_ = 0\n",
    "\n",
    "    def reset(self, mode, transaction_cost = 1e-7):\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.t_ = random.randint(0, self.split_)\n",
    "            self.end_t_ = self.split_\n",
    "\n",
    "        elif mode == 'test':\n",
    "            self.t_ = self.split_\n",
    "            self.end_t_ = len(self.data)-1\n",
    "\n",
    "        self.current_allocations = np.zeros((self.data.shape[1]))\n",
    "        self.transaction_cost = transaction_cost\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def get_return(self, allocations):\n",
    "        \n",
    "        return (self.data[self.t_, : , -2] * self.data[self.t_, : , -1] * allocations.detach().cpu().numpy()).sum()\n",
    "\n",
    "    def get_state(self):\n",
    "        \n",
    "        return torch.from_numpy(self.data[self.t_ , : , :-1]).to(device).to(torch.float32)\n",
    "\n",
    "    def is_end(self):\n",
    "        return self.t_ > self.end_t_\n",
    "\n",
    "    def step(self, allocations):\n",
    "\n",
    "        return_ = self.get_return(allocations)\n",
    "        self.t_ = self.t_ + self.holding_period\n",
    "        state_ = self.get_state()\n",
    "        is_end = self.is_end()\n",
    "\n",
    "        return state_, return_, is_end, self.transaction_cost\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_fpath = '/home/naradaw/dev/Charles_Schwab/data/historical/2024_09_11/historical_price_seq_2024_09_11_12_04.pkl'\n",
    "\n",
    "with open(pkl_fpath, 'rb') as f:\n",
    "    price_sqs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 61)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sqs_dict['A'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_symbol_uni = random.choices(list(price_sqs_dict.keys()), k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_constructor_sb = PortfolioConstructor(\n",
    "    device= device,\n",
    "    symbol_universe = test_symbol_uni,\n",
    "    seq_length = 60,\n",
    "    multihead_dim = 2,\n",
    "    num_transformer_layers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PortfolioConstructor(\n",
       "  (SREM): SREM(\n",
       "    (transformer_encoder_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=60, out_features=60, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "      (norm1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=60, out_features=60, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (norm1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ff): Linear(in_features=60, out_features=30, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (CAAN): CAAN(\n",
       "    (W_Q): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_K): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_V): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_O): Linear(in_features=15, out_features=30, bias=True)\n",
       "    (normalizer): LayerNorm((15,), eps=1e-05, elementwise_affine=True)\n",
       "    (scorer): Linear(in_features=15, out_features=1, bias=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_constructor_sb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_env = MarketEnvironment(\n",
    "    data_path = pkl_fpath,\n",
    "    holding_period = 1,\n",
    "    train_test_split= 0.8,\n",
    "    symbol_universe = test_symbol_uni\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 20, 61)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "transaction_costs = []\n",
    "market_env.reset(mode = 'train')\n",
    "state_ = market_env.get_state()\n",
    "is_end_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not is_end_:\n",
    "    chosen, portfolio = portfolio_constructor_sb(state_)\n",
    "    state_, reward_, is_end_, trans_cost = market_env.step(portfolio)\n",
    "    rewards.append(reward_)\n",
    "    transaction_costs.append(trans_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.58316117,  -7.28032087,   7.57444846,   4.73028908,\n",
       "        10.07012079,   0.09037463,  -1.45279456,   1.17449401,\n",
       "         1.96075105,  -3.17935164,  -2.4959386 ,   5.44669044,\n",
       "         5.5739951 ,   1.94999782,  -2.57326119, -10.90192575,\n",
       "        16.67943423,  -9.38908936,  10.05504363,  -1.42166629,\n",
       "        10.41073215,  -4.1050796 ,  -7.88177713,  12.97902375,\n",
       "        18.0587627 ,  -2.22916579,   1.25358838,   0.4022629 ,\n",
       "        -3.25438022,  11.33583267,  -1.95157867,   1.73196586,\n",
       "         3.21365214,  -5.21944285,   3.01302067])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_tt = np.array(rewards.copy())\n",
    "rewards_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.765301335596612"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = rewards_tt.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.Tensor(rewards_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sharpe ratio measures the excess return of the portfolio over the \n",
    "volatility of it -> risk adjusted performance\n",
    "'''\n",
    "\n",
    "\n",
    "def sharp_ratio_(rewards, tran_costs):\n",
    "\trewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25358556713127106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharp_ratio_(rewards, transaction_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PortfolioConstructor(\n",
       "  (SREM): SREM(\n",
       "    (transformer_encoder_layer): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=60, out_features=60, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "      (norm1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=60, out_features=60, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=60, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=60, bias=True)\n",
       "          (norm1): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ff): Linear(in_features=60, out_features=30, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (CAAN): CAAN(\n",
       "    (W_Q): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_K): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_V): Linear(in_features=30, out_features=15, bias=True)\n",
       "    (W_O): Linear(in_features=15, out_features=30, bias=True)\n",
       "    (normalizer): LayerNorm((15,), eps=1e-05, elementwise_affine=True)\n",
       "    (scorer): Linear(in_features=15, out_features=1, bias=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((60,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_creator_model = PortfolioConstructor(\n",
    "    device= device,\n",
    "    symbol_universe = test_symbol_uni,\n",
    "    seq_length = 60,\n",
    "    multihead_dim = 2,\n",
    "    num_transformer_layers = 2\n",
    ")\n",
    "\n",
    "port_creator_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MarketEnvironment at 0x7fa1800068e0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env = MarketEnvironment(\n",
    "    data_path = pkl_fpath,\n",
    "    holding_period = 1,\n",
    "    train_test_split= 0.8,\n",
    "    symbol_universe = test_symbol_uni\n",
    "    )\n",
    "\n",
    "market_env.reset(mode = 'train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
