{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PortfolioConstructor import PortfolioConstructor\n",
    "from ExchnageEnv import MarketEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda') \n",
    "    torch.get_default_device()\n",
    "    device = 'cuda'\n",
    "    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_fpath = '/home/naradaw/dev/Charles_Schwab/data/historical_random_100/2024_10_15/historical_price_seq_2024_10_15_16_22.pkl'\n",
    "\n",
    "with open(pkl_fpath, 'rb') as f:\n",
    "    price_sqs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sqs_dict[list(price_sqs_dict.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_universe = list(price_sqs_dict.keys())\n",
    "len(symbol_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_symbol_uni = random.choices(list(price_sqs_dict.keys()), k = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "portfolio_constructor = PortfolioConstructor(\n",
    "    device= device,\n",
    "    symbol_universe = symbol_universe,\n",
    "    seq_length = 60,\n",
    "    multihead_dim = 2,\n",
    "    num_transformer_layers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_env = MarketEnvironment(\n",
    "    data_path = pkl_fpath,\n",
    "    holding_period = 1,\n",
    "    train_test_split= 0.8,\n",
    "    symbol_universe = symbol_universe,\n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 100, 61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sharpe ratio measures the excess return of the portfolio over the \n",
    "volatility of it -> risk adjusted performance\n",
    "'''\n",
    "\n",
    "\n",
    "def sharp_ratio_(rewards, tran_costs):\n",
    "\n",
    "\t# rewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_constructor.cuda()\n",
    "portfolio_constructor.train()\n",
    "market_env.reset(mode = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f090ab825f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_constructor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(portfolio_constructor.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[149.8100, 150.2500, 145.8600,  ..., 131.0100, 132.2100, 132.8400],\n",
       "        [186.5200, 183.2800, 188.7600,  ..., 183.9000, 186.3400, 187.0000],\n",
       "        [219.0800, 214.2200, 217.1900,  ..., 214.1700, 220.3600, 218.3800],\n",
       "        ...,\n",
       "        [ 35.9000,  36.3900,  36.8200,  ...,  33.6900,  34.1100,  34.2700],\n",
       "        [ 88.7900,  86.5700,  88.7800,  ...,  88.0600,  89.1200,  89.2200],\n",
       "        [152.5200, 149.5800, 155.0300,  ..., 151.1900, 153.3600, 157.7400]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp_ratio_loss_(rewards, tran_costs, allocations):\n",
    "\n",
    "\t# rewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 500\n",
    "eval_step = 32\n",
    "train_step = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env):\n",
    "    model.eval()\n",
    "    is_end = False\n",
    "    rewards = []\n",
    "    tran_costs = []\n",
    "    \n",
    "    env.reset(mode = \"test\")\n",
    "    state = env.get_state()\n",
    "\n",
    "    while not is_end:\n",
    "        symbol_idx , allocations = model(state)\n",
    "        state, reward, is_end, tran_cost = env.step(allocations)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        tran_costs.append(tran_cost)\n",
    "\n",
    "    # print()\n",
    "    # print(\"evaluation\")\n",
    "    # print(f\"rewards : {rewards}\")\n",
    "    # print(f\"tran_costs : {tran_costs}\")\n",
    "    # print()\n",
    "\n",
    "    sharp_ratio = sharp_ratio_(rewards, tran_costs)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return sharp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "training model --\n",
      "Step 31: last loss = -87.33910\n",
      "eval step --\n",
      "Step 31: val_rewards = -0.0032945660973629316\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 63: last loss = -105.36764\n",
      "eval step --\n",
      "Step 63: val_rewards = 0.03494951313978346\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 95: last loss = -59.76510\n",
      "eval step --\n",
      "Step 95: val_rewards = 0.7129135422836762\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 127: last loss = -73.90375\n",
      "eval step --\n",
      "Step 127: val_rewards = 0.7437895064767789\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 159: last loss = -41.08833\n",
      "eval step --\n",
      "Step 159: val_rewards = 0.6969566369259936\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 191: last loss = 134.43474\n",
      "eval step --\n",
      "Step 191: val_rewards = 0.6306652273859508\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 223: last loss = 52.29326\n",
      "eval step --\n",
      "Step 223: val_rewards = 0.6915055001897352\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 255: last loss = 3.21008\n",
      "eval step --\n",
      "Step 255: val_rewards = 0.7440003324981059\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 287: last loss = -24.74278\n",
      "eval step --\n",
      "Step 287: val_rewards = 0.7593917207326308\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 319: last loss = 25.00805\n",
      "eval step --\n",
      "Step 319: val_rewards = 0.8159766044759166\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 351: last loss = 24.75091\n",
      "eval step --\n",
      "Step 351: val_rewards = 0.7952127825337196\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 383: last loss = -151.20958\n",
      "eval step --\n",
      "Step 383: val_rewards = 0.8271548086390452\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 415: last loss = -77.92056\n",
      "eval step --\n",
      "Step 415: val_rewards = 0.8287445873288591\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 447: last loss = -9.79541\n",
      "eval step --\n",
      "Step 447: val_rewards = 0.8287457887899594\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 479: last loss = 62.47225\n",
      "eval step --\n",
      "Step 479: val_rewards = 0.8287459545683473\n",
      "*** found better model ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_reward = -1\n",
    "\n",
    "for training_step in range(training_steps):\n",
    "    is_end = False\n",
    "    rewards = []\n",
    "    tran_costs = []\n",
    "    nlls = []\n",
    "\n",
    "    market_env.reset(mode = \"train\", transaction_cost= 1e-7)\n",
    "    state = market_env.get_state()\n",
    "\n",
    "    while not is_end:\n",
    "        symbol_idx, allocations = portfolio_constructor(state)\n",
    "        state, reward, is_end, tran_cost = market_env.step(allocations)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        tran_costs.append(tran_cost)\n",
    "        mask_tensor = torch.tensor([1 if i in symbol_idx.cpu().numpy() else 0 for i in range(allocations.shape[0])]).type(torch.FloatTensor).cuda()\n",
    "        # nlls.append(torch.log(allocations.abs() / 2 + 1e-9) * mask_tensor)\n",
    "        nlls.append(-(torch.log(allocations.abs() / 2 + 1e-9) * mask_tensor))\n",
    "\n",
    "    \n",
    "    sharp_ratio = sharp_ratio_(rewards, tran_costs)\n",
    "    loss = -sharp_ratio * sum([e.sum() for e in nlls])\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    if (training_step + 1) % train_step == 0:\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"training model --\")\n",
    "        print('Step {}: last loss = {:.5f}\\r'.format(training_step, loss), end='')\n",
    "        print()\n",
    "        writer.add_scalar(\"Loss/train\", sharp_ratio, training_step)\n",
    "        # pprint([(n, e.grad) for n, e in model.named_parameters()])\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        count = 0\n",
    "        \n",
    "    if (training_step + 1) % eval_step == 0:\n",
    "        print(\"eval step --\")\n",
    "        with torch.no_grad():\n",
    "            reward_val = evaluate(portfolio_constructor, market_env)\n",
    "            print('Step {}: val_rewards = {}'.format(training_step, reward_val))\n",
    "            writer.add_scalar(\"eval_sharpe/train\", reward_val, training_step)\n",
    "\n",
    "            if max_reward < reward_val:\n",
    "                max_reward = reward_val\n",
    "\n",
    "                print(\"*** found better model ***\")\n",
    "            print()\n",
    "                # torch.save(portfolio_constructor.state_dict(), model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114.29, 114.03, 114.48, ..., 126.04, 127.31, 129.41],\n",
       "       [148.21, 149.83, 149.36, ..., 176.96, 177.38, 182.95],\n",
       "       [217.1 , 218.18, 210.12, ..., 253.89, 260.55, 272.77],\n",
       "       ...,\n",
       "       [ 42.01,  41.65,  41.64, ...,  35.43,  35.26,  35.24],\n",
       "       [ 88.24,  84.98,  84.82, ...,  95.76,  95.81,  98.74],\n",
       "       [142.64, 140.48, 140.27, ..., 162.5 , 163.19, 167.59]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = market_env.get_random_state()\n",
    "random_state.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([32, 74, 10, 79, 18, 83, 22, 23, 87, 26], device='cuda:0'),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000, 0.0000, 0.0000, 0.1000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1000, 0.0000, 0.0000, 0.0000, 0.1000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_constructor(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(portfolio_constructor, random_state.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
