{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PortfolioConstructor import PortfolioConstructor\n",
    "from ExchnageEnv import MarketEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda') \n",
    "    torch.get_default_device()\n",
    "    device = 'cuda'\n",
    "    \n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_fpath = '/home/naradaw/dev/Charles_Schwab/data/historical_random_100/2024_10_15/historical_price_seq_2024_10_15_16_22.pkl'\n",
    "\n",
    "with open(pkl_fpath, 'rb') as f:\n",
    "    price_sqs_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sqs_dict[list(price_sqs_dict.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_universe = list(price_sqs_dict.keys())\n",
    "len(symbol_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_symbol_uni = random.choices(list(price_sqs_dict.keys()), k = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/miniconda3/envs/tf-wsl/lib/python3.9/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "portfolio_constructor = PortfolioConstructor(\n",
    "    device= device,\n",
    "    symbol_universe = symbol_universe,\n",
    "    seq_length = 60,\n",
    "    multihead_dim = 2,\n",
    "    num_transformer_layers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_env = MarketEnvironment(\n",
    "    data_path = pkl_fpath,\n",
    "    holding_period = 1,\n",
    "    train_test_split= 0.8,\n",
    "    symbol_universe = symbol_universe,\n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 100, 61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "sharpe ratio measures the excess return of the portfolio over the \n",
    "volatility of it -> risk adjusted performance\n",
    "'''\n",
    "\n",
    "\n",
    "def sharp_ratio_(rewards, tran_costs):\n",
    "\n",
    "\t# rewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_constructor.cuda()\n",
    "portfolio_constructor.train()\n",
    "market_env.reset(mode = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f85481347b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_constructor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(portfolio_constructor.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[121.5000, 120.6800, 116.4500,  ..., 129.1800, 129.3300, 130.3400],\n",
       "        [117.2400, 116.6700, 116.9600,  ..., 141.1400, 139.4600, 139.6500],\n",
       "        [147.6800, 148.4200, 141.9300,  ..., 152.9100, 154.4500, 154.4600],\n",
       "        ...,\n",
       "        [ 44.2800,  43.9700,  44.2900,  ...,  45.9100,  46.0100,  46.0700],\n",
       "        [ 73.6800,  73.8900,  73.2100,  ...,  85.6100,  86.2300,  85.4600],\n",
       "        [105.9000, 107.6400, 107.3000,  ..., 132.8500, 133.3600, 133.4900]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_env.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp_ratio_loss_(rewards, tran_costs, allocations):\n",
    "\n",
    "\t# rewards = [r.detach().cpu().numpy() for r in rewards]\n",
    "\tmean = sum(rewards) / len(rewards)\n",
    "\tAt = sum(r - t for r, t in zip(rewards, tran_costs)) / len(rewards)\n",
    "\tvol = sum((r - mean) ** 2 for r in rewards) / len(rewards)\n",
    "\tvol = vol ** 0.5\n",
    "\n",
    "\treturn (At - 1e-7) / (vol + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 500\n",
    "eval_step = 32\n",
    "train_step = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env):\n",
    "    model.eval()\n",
    "    is_end = False\n",
    "    rewards = []\n",
    "    tran_costs = []\n",
    "    \n",
    "    env.reset(mode = \"test\")\n",
    "    state = env.get_state()\n",
    "\n",
    "    while not is_end:\n",
    "        _ , allocations = model(state)\n",
    "        state, reward, is_end, tran_cost = env.step(allocations)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        tran_costs.append(tran_cost)\n",
    "\n",
    "    sharp_ratio = sharp_ratio_(rewards, tran_costs)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return sharp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "training model --\n",
      "Step 31: last loss = 45.61536\n",
      "eval step --\n",
      "Step 31: val_rewards = 0.4591165858777075\n",
      "*** found better model ***\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 63: last loss = 24.92854\n",
      "eval step --\n",
      "Step 63: val_rewards = 0.11485735874186744\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 95: last loss = 89.21492\n",
      "eval step --\n",
      "Step 95: val_rewards = -0.05456413280536202\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 127: last loss = 101.86233\n",
      "eval step --\n",
      "Step 127: val_rewards = -0.1003365504610342\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 159: last loss = 250.56691\n",
      "eval step --\n",
      "Step 159: val_rewards = -0.08374083424651758\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 191: last loss = 75.63830\n",
      "eval step --\n",
      "Step 191: val_rewards = -0.17835616320479927\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 223: last loss = 133.93294\n",
      "eval step --\n",
      "Step 223: val_rewards = 0.018871336395649266\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 255: last loss = 195.70557\n",
      "eval step --\n",
      "Step 255: val_rewards = 0.03703005738233949\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 287: last loss = 73.36045\n",
      "eval step --\n",
      "Step 287: val_rewards = 0.0022345676041224624\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 319: last loss = 39.64754\n",
      "eval step --\n",
      "Step 319: val_rewards = 0.10354561888997404\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 351: last loss = 88.57314\n",
      "eval step --\n",
      "Step 351: val_rewards = -0.05563050563362761\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 383: last loss = 73.36426\n",
      "eval step --\n",
      "Step 383: val_rewards = 0.09220452259461383\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 415: last loss = -40.18185\n",
      "eval step --\n",
      "Step 415: val_rewards = 0.06238522366081353\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 447: last loss = -14.21627\n",
      "eval step --\n",
      "Step 447: val_rewards = 0.15481545884156298\n",
      "\n",
      "-------------------------------------\n",
      "training model --\n",
      "Step 479: last loss = 28.70645\n",
      "eval step --\n",
      "Step 479: val_rewards = 0.1546818727975338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_reward = -1\n",
    "\n",
    "for training_step in range(training_steps):\n",
    "    is_end = False\n",
    "    rewards = []\n",
    "    tran_costs = []\n",
    "    nlls = []\n",
    "\n",
    "    market_env.reset(mode = \"train\", transaction_cost= 1e-7)\n",
    "    state = market_env.get_state()\n",
    "\n",
    "    while not is_end:\n",
    "        symbol_idx, allocations = portfolio_constructor(state)\n",
    "        state, reward, is_end, tran_cost = market_env.step(allocations)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        tran_costs.append(tran_cost)\n",
    "        mask_tensor = torch.tensor([1 if i in symbol_idx.cpu().numpy() else 0 for i in range(allocations.shape[0])]).type(torch.FloatTensor).cuda()\n",
    "        nlls.append(torch.log(allocations.abs() / 2 + 1e-9) * mask_tensor)\n",
    "        # nlls.append(-(torch.log(allocations.abs() / 2 + 1e-9) * mask_tensor))\n",
    "\n",
    "    \n",
    "    sharp_ratio = sharp_ratio_(rewards, tran_costs)\n",
    "    loss = -sharp_ratio * sum([e.sum() for e in nlls])\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    if (training_step + 1) % train_step == 0:\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"training model --\")\n",
    "        print('Step {}: last loss = {:.5f}\\r'.format(training_step, loss), end='')\n",
    "        print()\n",
    "        writer.add_scalar(\"Loss/train\", sharp_ratio, training_step)\n",
    "        # pprint([(n, e.grad) for n, e in model.named_parameters()])\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        count = 0\n",
    "        \n",
    "    if (training_step + 1) % eval_step == 0:\n",
    "        print(\"eval step --\")\n",
    "        with torch.no_grad():\n",
    "            reward_val = evaluate(portfolio_constructor, market_env)\n",
    "            print('Step {}: val_rewards = {}'.format(training_step, reward_val))\n",
    "            writer.add_scalar(\"eval_sharpe/train\", reward_val, training_step)\n",
    "\n",
    "            if max_reward < reward_val:\n",
    "                max_reward = reward_val\n",
    "\n",
    "                print(\"*** found better model ***\")\n",
    "            print()\n",
    "                # torch.save(portfolio_constructor.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140.85, 143.62, 143.96, ..., 132.63, 130.35, 129.18],\n",
       "       [239.24, 242.92, 243.09, ..., 252.98, 259.6 , 258.78],\n",
       "       [120.1 , 122.41, 130.58, ...,  99.82,  95.83,  95.08],\n",
       "       ...,\n",
       "       [ 40.47,  40.15,  39.78, ...,  39.74,  39.55,  39.95],\n",
       "       [ 79.5 ,  78.76,  79.79, ...,  77.43,  77.73,  77.74],\n",
       "       [205.58, 205.42, 205.19, ..., 211.91, 211.91, 212.57]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = market_env.get_random_state()\n",
    "random_state.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4, 68, 70,  6, 44, 13, 49, 18, 28, 95], device='cuda:0'),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0991, 0.0000, 0.0998, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1005, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1022, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0999, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0991,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0996, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1006, 0.0000, 0.0995, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0998, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000], device='cuda:0', grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_constructor(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradaw/dev/Charles_Schwab/code/RnD/enviroment/PortfolioConstructor.py:142: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  long_mask = torch.Tensor([0 if i in long_sqs else 1 for i in range(rank.shape[0])]).to(self.device)\n",
      "/home/naradaw/dev/Charles_Schwab/code/RnD/enviroment/PortfolioConstructor.py:170: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  portfolio_allocations = [allocation.item() for allocation in allocations if allocation != 0]\n"
     ]
    }
   ],
   "source": [
    "writer.add_graph(portfolio_constructor, random_state.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.3242, device='cuda:0'), tensor(-4.8283, device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor([0.4, 0.3, 0.3])).sum(), torch.log(torch.tensor([0.8, 0.1, 0.1])).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
